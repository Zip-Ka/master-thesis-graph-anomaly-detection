{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.1 --extra-index-url https://download.pytorch.org/whl/cu117\n"
      ],
      "metadata": {
        "id": "S4Nk03X6_Et1",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883545f7-3626-4089-b675-262a8545ed49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch==2.0.0+cu117 in /usr/local/lib/python3.11/dist-packages (2.0.0+cu117)\n",
            "Requirement already satisfied: torchvision==0.15.1+cu117 in /usr/local/lib/python3.11/dist-packages (0.15.1+cu117)\n",
            "Requirement already satisfied: torchaudio==2.0.1 in /usr/local/lib/python3.11/dist-packages (2.0.1+cu117)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0+cu117) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0+cu117) (4.13.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0+cu117) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0+cu117) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0+cu117) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.0+cu117) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1+cu117) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1+cu117) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.1+cu117) (11.1.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0+cu117) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.0+cu117) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.0+cu117) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1+cu117) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1+cu117) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1+cu117) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.1+cu117) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.0+cu117) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n"
      ],
      "metadata": {
        "id": "tRCWZXHF5W5D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c710b72-2311-4f80-a1f0-191303ebdefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.8)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.29.4)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.24.1)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.2.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "pou0C2xeIH-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28f17949-d017-4442-9ba7-edc1862ad512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mziprikk\u001b[0m (\u001b[33mziprikk-university-duisburg\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall pandas torch-scatter torch-sparse torch-cluster torch-spline-conv optuna torch-geometric deeprobust numpy -y"
      ],
      "metadata": {
        "id": "d6h4VldlIqT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"pandas==2.2.2\" \"numpy<2.0,>=1.18.5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSHlVaPwJpmF",
        "outputId": "2897fa68-6634-43b7-c908-b9f55c1ef4c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas==2.2.2 in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.2) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
        "!pip install optuna\n",
        "!pip install torch-geometric\n",
        "!pip install deeprobust"
      ],
      "metadata": {
        "id": "VTAS6l4aYMBZ",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9481395-8a5d-49a7-d550-d175aa5a89e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2+pt20cu117)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.11/dist-packages (0.6.18+pt20cu117)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3+pt20cu117)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (1.26.4)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.0.0+cu117.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.11/dist-packages (1.2.2+pt20cu117)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: deeprobust in /usr/local/lib/python3.11/dist-packages (0.2.11)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (2.0.0+cu117)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.13.1)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (0.15.1+cu117)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.7.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (3.4.2)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (0.60.0)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (11.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (0.25.2)\n",
            "Requirement already satisfied: tensorboardX>=2.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (2.6.2.2)\n",
            "Requirement already satisfied: tqdm>=3.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (4.67.1)\n",
            "Requirement already satisfied: gensim>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (4.3.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.3.0->deeprobust) (7.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.48.0->deeprobust) (0.43.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.0->deeprobust) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.0->deeprobust) (2025.3.13)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.0->deeprobust) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.1->deeprobust) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.1->deeprobust) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.0->deeprobust) (5.29.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (4.13.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.2.0->deeprobust) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.2.0->deeprobust) (18.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.4.0->deeprobust) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->deeprobust) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4.3.0->deeprobust) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->deeprobust) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.2.0->deeprobust) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "!pip install torch-geometric\n",
        "!pip install deeprobust"
      ],
      "metadata": {
        "id": "y9iTmscsusUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d625347-feda-4782-e8f7-eca2cf8706fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.2.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.15.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.14)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.2.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: deeprobust in /usr/local/lib/python3.11/dist-packages (0.2.11)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.17.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (2.0.0+cu117)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.13.1)\n",
            "Requirement already satisfied: torchvision>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (0.15.1+cu117)\n",
            "Requirement already satisfied: texttable>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.7.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (3.4.2)\n",
            "Requirement already satisfied: numba>=0.48.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (0.60.0)\n",
            "Requirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (11.1.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (0.25.2)\n",
            "Requirement already satisfied: tensorboardX>=2.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (2.6.2.2)\n",
            "Requirement already satisfied: tqdm>=3.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (4.67.1)\n",
            "Requirement already satisfied: gensim>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from deeprobust) (4.3.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim>=4.3.0->deeprobust) (7.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.1.1->deeprobust) (2.8.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.48.0->deeprobust) (0.43.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.0->deeprobust) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.0->deeprobust) (2025.3.13)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.0->deeprobust) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.1->deeprobust) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.1->deeprobust) (3.6.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX>=2.0->deeprobust) (5.29.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (4.13.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (1.13.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (3.1.6)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.2.0->deeprobust) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.2.0->deeprobust) (3.31.6)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch>=1.2.0->deeprobust) (18.1.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.4.0->deeprobust) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.1.1->deeprobust) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim>=4.3.0->deeprobust) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.2.0->deeprobust) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision>=0.4.0->deeprobust) (2025.1.31)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.2.0->deeprobust) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv, SAGEConv\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "print(f\"Torch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"PyTorch Geometric version: {torch_geometric.__version__}\")\n"
      ],
      "metadata": {
        "id": "mwECxhBiB1ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1f56b7-555a-4831-ff21-549e0562a251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 2.0.0+cu117\n",
            "CUDA available: True\n",
            "PyTorch Geometric version: 2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard library imports\n",
        "import json\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "import gc\n",
        "from contextlib import nullcontext\n",
        "from copy import deepcopy\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "import concurrent.futures\n",
        "import io\n",
        "import pickle\n",
        "import warnings\n",
        "import zlib\n",
        "from wandb.sdk.wandb_run import Run\n",
        "# Third-party imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import optuna\n",
        "import psutil\n",
        "import wandb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    average_precision_score,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    matthews_corrcoef,\n",
        "    precision_recall_curve,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from tqdm import tqdm\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.multiprocessing as mp\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.distributed import destroy_process_group, init_process_group\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.optim.lr_scheduler import LinearLR, OneCycleLR, ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from torch_geometric.nn import MessagePassing, SAGEConv\n",
        "from torch_geometric.transforms import BaseTransform\n",
        "from torch_geometric.utils import to_networkx\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "import optuna\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "from sklearn.metrics import (\n",
        "    f1_score, roc_auc_score, precision_recall_curve, auc,\n",
        "    average_precision_score, confusion_matrix, jaccard_score,\n",
        "    matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score\n",
        ")\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch_geometric.loader import NeighborLoader\n",
        "from sklearn.utils import compute_class_weight\n",
        "\n",
        "import copy\n",
        "import deeprobust.graph.utils as utils\n",
        "from google.colab import drive\n",
        "from sklearn.metrics import recall_score\n",
        "import warnings\n",
        "from typing import Optional\n",
        "import numpy as np\n",
        "from sklearn.metrics import (\n",
        "    precision_recall_curve, auc, jaccard_score,\n",
        "    confusion_matrix, matthews_corrcoef, cohen_kappa_score,\n",
        "    balanced_accuracy_score, average_precision_score\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from typing import List, Dict, Tuple\n",
        "warnings.filterwarnings('ignore', message='.*pyg-lib.*')\n"
      ],
      "metadata": {
        "id": "ket_yElrPcUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedModelTrainer:\n",
        "\n",
        "    def __init__(self, checkpoint_dir: str, wandb_project: str,\n",
        "                    wandb_entity: str, wandb_run=None, oversample_ratio=50.0):\n",
        "\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        print(f\"\\nUsing device: {self.device}\")\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "\n",
        "            print(f\"Initial GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e6:.2f} MB\")\n",
        "            print(f\"Initial GPU memory cached: {torch.cuda.memory_reserved(0) / 1e6:.2f} MB\")\n",
        "\n",
        "        self.data_handler = DataHandler(checkpoint_dir, device=self.device)\n",
        "\n",
        "        raw_edges, raw_features = self.data_handler.load_preprocessed_data()\n",
        "\n",
        "        self.raw_features = raw_features.copy()\n",
        "\n",
        "        self.df_features, self.df_edges = DataHandler.preprocess_with_smote(\n",
        "            raw_features, raw_edges,\n",
        "            oversample_ratio=oversample_ratio,\n",
        "            start_timestep=1,\n",
        "            end_timestep=36\n",
        "        )\n",
        "\n",
        "        self.wandb_project = wandb_project\n",
        "        self.wandb_entity = wandb_entity\n",
        "        self.wandb_run = wandb_run\n",
        "\n",
        "        self.input_dim = len(self.df_features.columns.difference(\n",
        "            ['node_id', 'Time step', 'class', 'binary_class']\n",
        "        ))\n",
        "\n",
        "        feature_cols = self.df_features.columns.difference(['node_id', 'Time step', 'class', 'binary_class'])\n",
        "        print(\"\\nFeature details:\")\n",
        "        print(f\"Number of features: {len(feature_cols)}\")\n",
        "        print(\"\\nFeature names:\")\n",
        "        for i, col in enumerate(feature_cols, 1):\n",
        "            print(f\"{i}. {col}\")\n",
        "\n",
        "        print(\"\\nFeature statistics:\")\n",
        "        print(self.df_features[feature_cols].describe())\n",
        "\n",
        "        # Print original class distribution\n",
        "        print(\"\\nOriginal class distribution:\")\n",
        "        print(self.df_features['class'].value_counts().sort_index())\n",
        "\n",
        "        unique_classes = sorted(self.df_features['class'].unique())\n",
        "        print(f\"\\nUnique classes found in data: {unique_classes}\")\n",
        "\n",
        "        binary_classes = [c for c in unique_classes if c != 3]\n",
        "        print(f\"Classes used for binary classification: {binary_classes}\")\n",
        "\n",
        "        if len(binary_classes) != 2:\n",
        "            raise ValueError(f\"Expected 2 classes (excluding class 3), found {len(binary_classes)}: {binary_classes}\")\n",
        "\n",
        "\n",
        "        self.class_mapping = {1: 1, 2: 0}\n",
        "        self.df_features['binary_class'] = self.df_features['class'].map(lambda x: self.class_mapping.get(x, -1))\n",
        "        self.raw_features['binary_class'] = self.raw_features['class'].map(lambda x: self.class_mapping.get(x, -1))\n",
        "\n",
        "        print(f\"\\nClass mapping:\")\n",
        "        print(f\"Class {binary_classes[0]} → 0\")\n",
        "        print(f\"Class {binary_classes[1]} → 1\")\n",
        "        print(f\"Class 3 → -1 (excluded from training)\")\n",
        "\n",
        "        binary_mask = self.df_features['class'].isin(binary_classes)\n",
        "        self.train_mask = binary_mask & self.df_features['Time step'].between(1, 36)\n",
        "        self.val_mask = binary_mask & self.df_features['Time step'].between(37, 41)\n",
        "        self.test_mask = binary_mask & self.df_features['Time step'].between(42, 49)\n",
        "\n",
        "        print(\"\\nData split sizes (excluding class 3):\")\n",
        "        print(f\"Training nodes: {self.train_mask.sum()}\")\n",
        "        print(f\"Validation nodes: {self.val_mask.sum()}\")\n",
        "        print(f\"Test nodes: {self.test_mask.sum()}\")\n",
        "\n",
        "\n",
        "        self._print_class_distribution_per_split()\n",
        "\n",
        "        self.train_mask = torch.tensor(self.train_mask.values, dtype=torch.bool, device=self.device)\n",
        "        self.val_mask = torch.tensor(self.val_mask.values, dtype=torch.bool, device=self.device)\n",
        "        self.test_mask = torch.tensor(self.test_mask.values, dtype=torch.bool, device=self.device)\n",
        "\n",
        "        raw_binary_mask = self.raw_features['class'].isin(binary_classes)\n",
        "        raw_binary_classes_df = self.raw_features[raw_binary_mask]\n",
        "        raw_class_counts = raw_binary_classes_df['binary_class'].value_counts()\n",
        "\n",
        "        self.class_weights = torch.tensor(\n",
        "            [1.0 / (raw_class_counts[i] / len(raw_binary_classes_df)) for i in range(2)],\n",
        "            dtype=torch.float32,\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        print(\"\\nClass weights calculated on RAW data (before oversampling):\")\n",
        "        print(f\"Class 0 weight: {self.class_weights[0]:.4f}\")\n",
        "        print(f\"Class 1 weight: {self.class_weights[1]:.4f}\")\n",
        "\n",
        "        if self.wandb_run is not None:\n",
        "            self.wandb_run.config.update({\n",
        "                \"binary_class_distribution\": raw_class_counts.to_dict(),\n",
        "                \"class_3_nodes\": len(self.raw_features[self.raw_features['class'] == 3]),\n",
        "                \"class_mapping\": self.class_mapping,\n",
        "                \"train_nodes\": self.train_mask.sum().item(),\n",
        "                \"val_nodes\": self.val_mask.sum().item(),\n",
        "                \"test_nodes\": self.test_mask.sum().item(),\n",
        "                \"oversample_timesteps\": \"1-36 only\"  # Added to track this configuration\n",
        "            })\n",
        "\n",
        "        all_timesteps = sorted(self.df_features['Time step'].unique())\n",
        "        self.train_timesteps = [ts for ts in all_timesteps if 1 <= ts <= 36]\n",
        "        self.val_timesteps = [ts for ts in all_timesteps if 37 <= ts <= 41]\n",
        "        self.test_timesteps = [ts for ts in all_timesteps if 42 <= ts <= 49]\n",
        "\n",
        "    def extract_node_embeddings(self, model, timesteps=None, output_path=None):\n",
        "\n",
        "        model.eval()\n",
        "        data_list = []\n",
        "\n",
        "        if timesteps is None:\n",
        "            timesteps = sorted(self.df_features['Time step'].unique())\n",
        "\n",
        "        if hasattr(model, 'num_neighbors'):\n",
        "            num_neighbors_param = model.num_neighbors\n",
        "        else:\n",
        "            num_neighbors_param = [15]\n",
        "\n",
        "        print(f\"Using num_neighbors: {num_neighbors_param}\")\n",
        "        print(\"Model structure:\")\n",
        "        print(model)\n",
        "\n",
        "        print(\"\\nModel modules:\")\n",
        "        for name, module in model.named_modules():\n",
        "            print(f\"  {name}: {type(module).__name__}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for timestep in timesteps:\n",
        "                print(f\"Processing timestep {timestep}\")\n",
        "\n",
        "                try:\n",
        "                    data = self.data_handler.process_timestep_with_sampling(\n",
        "                        self.df_edges,\n",
        "                        self.df_features,\n",
        "                        timestep,\n",
        "                        num_neighbors=num_neighbors_param\n",
        "                    ).to(self.device)\n",
        "                    valid_mask = (data.y != -1)\n",
        "                    if valid_mask.sum() == 0:\n",
        "                        print(f\"  No valid nodes for timestep {timestep}\")\n",
        "                        continue\n",
        "\n",
        "                    embeddings_container = []\n",
        "\n",
        "                    def input_hook_fn(module, input):\n",
        "\n",
        "                        if isinstance(input, tuple) and len(input) > 0:\n",
        "                            embeddings_container.append(input[0].detach())\n",
        "\n",
        "                    def output_hook_fn(module, input, output):\n",
        "\n",
        "                        embeddings_container.append(output.detach())\n",
        "\n",
        "                    final_layer = None\n",
        "\n",
        "\n",
        "                    for name, module in model.named_modules():\n",
        "                        if isinstance(module, torch.nn.Linear):\n",
        "\n",
        "                            if module.out_features == 2:\n",
        "                                final_layer = module\n",
        "                                print(f\"Found final classification layer: {name}\")\n",
        "                                break\n",
        "\n",
        "                    if final_layer:\n",
        "                        hook = final_layer.register_forward_pre_hook(input_hook_fn)\n",
        "                        print(\"Using pre-hook on classification layer to capture embeddings\")\n",
        "                    else:\n",
        "\n",
        "                        for name, module in model.named_modules():\n",
        "                            if any(conv_name in type(module).__name__.lower() for conv_name in\n",
        "                                  ['conv', 'sage', 'gat', 'gcn']):\n",
        "                                final_layer = module\n",
        "                                print(f\"Found graph convolution layer: {name}\")\n",
        "                                break\n",
        "\n",
        "                        if final_layer:\n",
        "                            # Hook the output of the graph conv layer\n",
        "                            hook = final_layer.register_forward_hook(output_hook_fn)\n",
        "                            print(\"Using hook on graph convolution layer to capture embeddings\")\n",
        "                        else:\n",
        "\n",
        "                            for name, module in model.named_modules():\n",
        "                                if isinstance(module, torch.nn.Module) and not isinstance(module, torch.nn.Sequential):\n",
        "                                    if len(list(module.parameters())) > 0:\n",
        "                                        final_layer = module\n",
        "                                        print(f\"Using fallback layer: {name}\")\n",
        "                                        break\n",
        "\n",
        "                            if final_layer:\n",
        "                                hook = final_layer.register_forward_hook(output_hook_fn)\n",
        "                                print(\"Using fallback hook\")\n",
        "                            else:\n",
        "                                raise ValueError(\"Could not find any suitable layer for hooking\")\n",
        "\n",
        "                    _ = model(data.x, data.edge_index)\n",
        "\n",
        "                    hook.remove()\n",
        "\n",
        "                    if not embeddings_container:\n",
        "                        raise ValueError(\"No embeddings captured by hook\")\n",
        "\n",
        "                    node_embeddings = embeddings_container[0]\n",
        "                    print(f\"Captured embeddings shape: {node_embeddings.shape}\")\n",
        "\n",
        "                    embeddings_np = node_embeddings.cpu().numpy()\n",
        "\n",
        "                    original_node_ids = self.df_features[self.df_features['Time step'] == timestep]['node_id'].values\n",
        "\n",
        "                    if len(original_node_ids) != embeddings_np.shape[0]:\n",
        "                        print(f\"Warning: Number of node IDs ({len(original_node_ids)}) doesn't match number of embeddings ({embeddings_np.shape[0]})\")\n",
        "\n",
        "                        if len(original_node_ids) > embeddings_np.shape[0]:\n",
        "\n",
        "                            timestep_mask = self.df_features['Time step'] == timestep\n",
        "                            node_ids_mask = np.isin(self.df_features[timestep_mask]['node_id'].values, data.batch.cpu().numpy())\n",
        "\n",
        "                            original_node_ids = self.df_features[timestep_mask]['node_id'].values[node_ids_mask]\n",
        "                            print(f\"Adjusted node IDs count: {len(original_node_ids)}\")\n",
        "\n",
        "                        min_length = min(len(original_node_ids), embeddings_np.shape[0])\n",
        "                        original_node_ids = original_node_ids[:min_length]\n",
        "                        embeddings_np = embeddings_np[:min_length]\n",
        "\n",
        "                    # Get labels\n",
        "                    labels = data.y.cpu().numpy()\n",
        "                    if len(labels) != embeddings_np.shape[0]:\n",
        "                        print(f\"Warning: Number of labels ({len(labels)}) doesn't match number of embeddings ({embeddings_np.shape[0]})\")\n",
        "                        # Use the minimum to avoid errors\n",
        "                        min_length = min(len(labels), embeddings_np.shape[0])\n",
        "                        labels = labels[:min_length]\n",
        "                        embeddings_np = embeddings_np[:min_length]\n",
        "\n",
        "                    df_timestep = pd.DataFrame(\n",
        "                        embeddings_np,\n",
        "                        columns=[f'embedding_{i}' for i in range(embeddings_np.shape[1])]\n",
        "                    )\n",
        "\n",
        "\n",
        "                    df_timestep['node_id'] = original_node_ids\n",
        "                    df_timestep['timestep'] = timestep\n",
        "                    df_timestep['label'] = labels\n",
        "\n",
        "                    data_list.append(df_timestep)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing timestep {timestep}: {str(e)}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "                finally:\n",
        "\n",
        "                    if 'data' in locals():\n",
        "                        del data\n",
        "                    if 'node_embeddings' in locals():\n",
        "                        del node_embeddings\n",
        "                    if 'embeddings_container' in locals():\n",
        "                        del embeddings_container\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "        if not data_list:\n",
        "            print(\"No embeddings extracted!\")\n",
        "            return None\n",
        "\n",
        "        df_embeddings = pd.concat(data_list, ignore_index=True)\n",
        "        if output_path:\n",
        "            try:\n",
        "                print(f\"Saving embeddings to {output_path}\")\n",
        "                temp_path = \"temp_node_embeddings.parquet\"\n",
        "                df_embeddings.to_parquet(temp_path)\n",
        "\n",
        "\n",
        "                import shutil\n",
        "                if output_path != temp_path:\n",
        "                    shutil.move(temp_path, output_path)\n",
        "\n",
        "                print(f\"Saved embeddings successfully!\")\n",
        "                print(f\"Total rows: {len(df_embeddings)}\")\n",
        "                print(f\"Number of embedding dimensions: {df_embeddings.columns.str.startswith('embedding_').sum()}\")\n",
        "                print(f\"Number of unique nodes: {df_embeddings['node_id'].nunique()}\")\n",
        "                print(f\"Number of timesteps: {df_embeddings['timestep'].nunique()}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving file: {str(e)}\")\n",
        "                import os\n",
        "                if os.path.exists(temp_path):\n",
        "                    os.remove(temp_path)\n",
        "                    print(\"Cleaned up temporary file\")\n",
        "\n",
        "        return df_embeddings\n",
        "\n",
        "    def get_embeddings(self, x, edge_index, edge_weight=None, model=None):\n",
        "\n",
        "        if model is None:\n",
        "            raise ValueError(\"Model must be provided to extract embeddings\")\n",
        "\n",
        "        x = F.dropout(x, p=model.dropout, training=model.training)\n",
        "\n",
        "        for i, conv in enumerate(model.convs[:-1]):\n",
        "            if edge_weight is not None:\n",
        "                x_new = conv(x, edge_index, edge_weight)\n",
        "            else:\n",
        "                x_new = conv(x, edge_index)\n",
        "\n",
        "            if hasattr(model, 'residual') and model.residual and x.size() == x_new.size():\n",
        "                x = x_new + x\n",
        "            else:\n",
        "                x = x_new\n",
        "\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=model.dropout, training=model.training)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def calculate_composite_score(self, y_true: np.ndarray, y_pred: np.ndarray, y_prob: np.ndarray) -> float:\n",
        "        balanced_acc = balanced_accuracy_score(y_true, y_pred)\n",
        "        tp = np.sum((y_true == 1) & (y_pred == 1))\n",
        "        fn = np.sum((y_true == 1) & (y_pred != 1))\n",
        "        fp = np.sum((y_true != 1) & (y_pred == 1))\n",
        "\n",
        "        minority_recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        minority_precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        minority_f1 = (2 * minority_precision * minority_recall / (minority_precision + minority_recall)\n",
        "                      if (minority_precision + minority_recall) > 0 else 0)\n",
        "        composite_score = 0.1 * balanced_acc + 0.5 * minority_f1 + 0.4 * minority_recall\n",
        "        return float(composite_score)\n",
        "\n",
        "    def find_optimal_threshold(self, y_true: np.ndarray, y_prob: np.ndarray, step: float = 0.01) -> float:\n",
        "        thresholds = np.arange(0.0, 1.0 + step, step)\n",
        "        best_score = -np.inf\n",
        "        best_threshold = 0.5\n",
        "        for threshold in thresholds:\n",
        "            y_pred = (y_prob >= threshold).astype(int)\n",
        "            score = self.calculate_composite_score(y_true, y_pred, y_prob)\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_threshold = threshold\n",
        "        return best_threshold\n",
        "\n",
        "    def _evaluate_on_test_sample(self, model, test_timesteps, num_neighbors):\n",
        "\n",
        "        test_metrics = []\n",
        "\n",
        "        for timestep in test_timesteps:\n",
        "            print(f\"Evaluating on test timestep {timestep}...\")\n",
        "\n",
        "            test_data = self.data_handler.process_timestep_with_sampling(\n",
        "                self.df_edges,\n",
        "                self.df_features,\n",
        "                timestep,\n",
        "                num_neighbors\n",
        "            ).to(self.device)\n",
        "\n",
        "            valid_mask = (test_data.y != -1)\n",
        "            if valid_mask.sum() == 0:\n",
        "                print(f\"  No valid nodes for timestep {timestep}\")\n",
        "                continue\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                out = model(test_data.x, test_data.edge_index)\n",
        "                out_valid = out[valid_mask]\n",
        "                probs = F.softmax(out_valid, dim=1)\n",
        "\n",
        "                y_test = test_data.y[valid_mask].cpu().numpy()\n",
        "                probs_np = probs.cpu().numpy()\n",
        "                preds_np = (probs_np[:, 1] >= self.optimal_threshold).astype(int)\n",
        "\n",
        "                if len(np.unique(y_test)) > 1:\n",
        "                    metrics = self.calculate_metrics(y_test, preds_np, probs_np)\n",
        "                    metrics['timestep'] = timestep\n",
        "                    test_metrics.append(metrics)\n",
        "\n",
        "\n",
        "                    print(f\"  Composite Score: {metrics.get('composite_score', 0):.4f}\")\n",
        "                    print(f\"  Class 1 Recall: {metrics.get('class_1_recall', 0):.4f}\")\n",
        "                    print(f\"  Class 1 F1: {metrics.get('class_1_f1', 0):.4f}\")\n",
        "                else:\n",
        "                    print(f\"  Only one class present in timestep {timestep}, skipping metrics\")\n",
        "\n",
        "                del test_data, out, probs\n",
        "\n",
        "\n",
        "        if test_metrics:\n",
        "            avg_metrics = {\n",
        "                k: np.mean([m.get(k, 0) for m in test_metrics if k in m])\n",
        "                for k in test_metrics[0].keys()\n",
        "                if k != 'timestep' and k != 'confusion_matrix'\n",
        "            }\n",
        "            return avg_metrics\n",
        "\n",
        "        return {'composite_score': 0.0}\n",
        "\n",
        "\n",
        "    def debug_mask_creation(self):\n",
        "        print(\"\\n=== Detailed Mask Class Distribution by Timestep ===\")\n",
        "        unique_classes = sorted(self.df_features['class'].unique())\n",
        "        print(f\"ALL Unique Classes in Dataset: {unique_classes}\")\n",
        "\n",
        "        timesteps = sorted(self.df_features['Time step'].unique())\n",
        "\n",
        "        print(f\"\\n{'Timestep':^10} | {'Total Nodes':^12} | \" +\n",
        "              \" | \".join([f\"{'Class ' + str(cls):^10}\" for cls in unique_classes]))\n",
        "        print(\"-\" * (50 + 12 * len(unique_classes)))\n",
        "\n",
        "        for ts in timesteps:\n",
        "            ts_data = self.df_features[self.df_features['Time step'] == ts]\n",
        "            class_counts = ts_data['class'].value_counts()\n",
        "            row_data = [\n",
        "                ts,\n",
        "                len(ts_data)\n",
        "            ] + [class_counts.get(cls, 0) for cls in unique_classes]\n",
        "\n",
        "            print(f\"{row_data[0]:^10} | {row_data[1]:^12} | \" +\n",
        "                  \" | \".join([f\"{count:^10}\" for count in row_data[2:]]))\n",
        "\n",
        "    def _print_class_distribution_per_split(self):\n",
        "\n",
        "        binary_mask = self.df_features['class'] != 3\n",
        "\n",
        "        print(\"\\n=== Class Distribution Per Split ===\")\n",
        "\n",
        "\n",
        "        train_data = self.df_features[binary_mask & self.df_features['Time step'].between(1, 36)]\n",
        "        train_class_dist = train_data['binary_class'].value_counts().sort_index()\n",
        "        print(\"\\nTraining set class distribution:\")\n",
        "        print(train_class_dist)\n",
        "        print(f\"Class 0 percentage: {100 * train_class_dist[0] / train_class_dist.sum():.2f}%\")\n",
        "        print(f\"Class 1 percentage: {100 * train_class_dist[1] / train_class_dist.sum():.2f}%\")\n",
        "        print(f\"Class ratio (0:1): 1:{train_class_dist[1] / train_class_dist[0]:.2f}\")\n",
        "\n",
        "\n",
        "        val_data = self.df_features[binary_mask & self.df_features['Time step'].between(37, 41)]\n",
        "        val_class_dist = val_data['binary_class'].value_counts().sort_index()\n",
        "        print(\"\\nValidation set class distribution:\")\n",
        "        print(val_class_dist)\n",
        "        print(f\"Class 0 percentage: {100 * val_class_dist[0] / val_class_dist.sum():.2f}%\")\n",
        "        print(f\"Class 1 percentage: {100 * val_class_dist[1] / val_class_dist.sum():.2f}%\")\n",
        "        print(f\"Class ratio (0:1): 1:{val_class_dist[1] / val_class_dist[0]:.2f}\")\n",
        "\n",
        "\n",
        "        test_data = self.df_features[binary_mask & self.df_features['Time step'].between(42, 49)]\n",
        "        test_class_dist = test_data['binary_class'].value_counts().sort_index()\n",
        "        print(\"\\nTest set class distribution:\")\n",
        "        print(test_class_dist)\n",
        "        print(f\"Class 0 percentage: {100 * test_class_dist[0] / test_class_dist.sum():.2f}%\")\n",
        "        print(f\"Class 1 percentage: {100 * test_class_dist[1] / test_class_dist.sum():.2f}%\")\n",
        "        print(f\"Class ratio (0:1): 1:{test_class_dist[1] / test_class_dist[0]:.2f}\")\n",
        "\n",
        "\n",
        "    def calculate_metrics(self, targets: np.ndarray, predictions: np.ndarray, probabilities: np.ndarray) -> Dict:\n",
        "        if len(targets) == 0 or len(predictions) == 0 or len(probabilities) == 0:\n",
        "            return {}\n",
        "\n",
        "        if predictions.ndim > 1 and predictions.shape[1] > 1:\n",
        "\n",
        "            predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "        if probabilities.ndim == 1:\n",
        "\n",
        "            probabilities = np.vstack((1 - probabilities, probabilities)).T\n",
        "\n",
        "        targets = targets.flatten()\n",
        "        predictions = predictions.flatten()\n",
        "\n",
        "        metrics = {}\n",
        "\n",
        "        try:\n",
        "\n",
        "            metrics['accuracy'] = (predictions == targets).mean()\n",
        "            metrics['balanced_accuracy'] = balanced_accuracy_score(targets, predictions)\n",
        "\n",
        "            unique_classes = np.unique(targets)\n",
        "            if len(unique_classes) < 2:\n",
        "                print(f\"Warning: Only class {unique_classes[0]} present in targets. Some metrics will be unavailable.\")\n",
        "                return {'accuracy': metrics['accuracy']}\n",
        "\n",
        "\n",
        "            metrics['precision'] = precision_score(targets, predictions)\n",
        "            metrics['recall'] = recall_score(targets, predictions)\n",
        "\n",
        "\n",
        "            metrics['f1'] = f1_score(targets, predictions, average=None)\n",
        "            metrics['f1_micro'] = f1_score(targets, predictions, average='micro')\n",
        "            metrics['f1_macro'] = f1_score(targets, predictions, average='macro')\n",
        "            metrics['f1_weighted'] = f1_score(targets, predictions, average='weighted')\n",
        "\n",
        "            metrics['auroc'] = roc_auc_score(targets, probabilities[:, 1])\n",
        "            metrics['auprc'] = average_precision_score(targets, probabilities[:, 1])\n",
        "\n",
        "            metrics['jaccard'] = jaccard_score(targets, predictions, average='weighted')\n",
        "            metrics['mcc'] = matthews_corrcoef(targets, predictions)\n",
        "            metrics['norm_mcc'] = (metrics['mcc'] + 1) / 2\n",
        "            metrics['kappa'] = cohen_kappa_score(targets, predictions)\n",
        "\n",
        "\n",
        "            metrics['confusion_matrix'] = confusion_matrix(targets, predictions)\n",
        "\n",
        "            precision, recall, _ = precision_recall_curve(targets, probabilities[:, 1])\n",
        "            metrics['pr_auc'] = auc(recall, precision)\n",
        "\n",
        "            for class_idx in range(2):\n",
        "                y_true_bin = (targets == class_idx)\n",
        "                y_pred_bin = (predictions == class_idx)\n",
        "\n",
        "                tp = np.logical_and(y_true_bin, y_pred_bin).sum()\n",
        "                fp = np.logical_and(np.logical_not(y_true_bin), y_pred_bin).sum()\n",
        "                fn = np.logical_and(y_true_bin, np.logical_not(y_pred_bin)).sum()\n",
        "\n",
        "                precision_val = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "                recall_val = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "\n",
        "                metrics[f'class_{class_idx}_precision'] = precision_val\n",
        "                metrics[f'class_{class_idx}_recall'] = recall_val\n",
        "                metrics[f'class_{class_idx}_f1'] = (2 * precision_val * recall_val) / (precision_val + recall_val) if (precision_val + recall_val) > 0 else 0\n",
        "                metrics[f'class_{class_idx}_jaccard'] = jaccard_score(\n",
        "                    targets == class_idx,\n",
        "                    predictions == class_idx\n",
        "                )\n",
        "\n",
        "                metrics[f'class_{class_idx}_accuracy'] = np.mean(predictions[targets == class_idx] == class_idx) if np.sum(targets == class_idx) > 0 else 0\n",
        "\n",
        "            metrics['composite_score'] = self.calculate_composite_score(targets, predictions, probabilities)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error calculating metrics: {str(e)}\")\n",
        "\n",
        "            try:\n",
        "                metrics = {\n",
        "                    'accuracy': (predictions == targets).mean(),\n",
        "                    'balanced_accuracy': balanced_accuracy_score(targets, predictions)\n",
        "                }\n",
        "            except Exception as e2:\n",
        "                print(f\"Error calculating basic metrics: {str(e2)}\")\n",
        "                metrics = {'error': str(e)}\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _objective(self, trial: optuna.Trial) -> float:\n",
        "\n",
        "        params = {\n",
        "\n",
        "            \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
        "\n",
        "            \"base_channels\": trial.suggest_int(\"base_channels\", 16, 256, step=16),\n",
        "\n",
        "            \"dropout\": trial.suggest_float(\"dropout\", 0.2, 0.6),\n",
        "\n",
        "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True),\n",
        "\n",
        "            \"weight_decay\": trial.suggest_float(\"weight_decay\", 1e-4, 5e-2, log=True),\n",
        "\n",
        "            \"residual\": trial.suggest_categorical(\"residual\", [False, True]),\n",
        "\n",
        "            \"activation\": trial.suggest_categorical(\"activation\", [\"relu\", \"leaky_relu\"]),\n",
        "\n",
        "            \"edge_dropout\": trial.suggest_float(\"edge_dropout\", 0.0, 0.3),\n",
        "\n",
        "            \"focal_gamma\": trial.suggest_float(\"focal_gamma\", 2.0, 3.0),\n",
        "\n",
        "            \"class_weight_factor\": trial.suggest_float(\"class_weight_factor\", 1.0, 20.0),\n",
        "\n",
        "            \"max_neighbors\": trial.suggest_int(\"max_neighbors\", 5, 35),\n",
        "        }\n",
        "        hidden_channels = []\n",
        "        aggregation_methods = []\n",
        "        num_neighbors = []\n",
        "\n",
        "        for i in range(params[\"num_layers\"]):\n",
        "            channels = trial.suggest_int(\n",
        "                f\"layer_{i}_channels\",\n",
        "                int(params[\"base_channels\"] * 0.5),\n",
        "                params[\"base_channels\"]\n",
        "            )\n",
        "            hidden_channels.append(channels)\n",
        "            aggregation_methods.append(\n",
        "                trial.suggest_categorical(\n",
        "                    f\"aggregation_layer_{i}\", [\"mean\", \"max\", \"sum\"]\n",
        "                )\n",
        "            )\n",
        "\n",
        "            num_neighbors.append(trial.suggest_int(\n",
        "                f\"neighbors_layer_{i}\",\n",
        "                5,\n",
        "                params[\"max_neighbors\"]\n",
        "            ))\n",
        "\n",
        "        params.update({\n",
        "            \"hidden_channels\": hidden_channels,\n",
        "            \"aggregation_methods\": aggregation_methods,\n",
        "            \"num_neighbors\": num_neighbors\n",
        "        })\n",
        "\n",
        "        train_timesteps = sorted([ts for ts in self.df_features['Time step'].unique() if 1 <= ts <= 36])\n",
        "        val_timesteps = sorted([ts for ts in self.df_features['Time step'].unique() if 37 <= ts <= 41])\n",
        "\n",
        "        print(f\"Training on timesteps {train_timesteps}\")\n",
        "        print(f\"Validating on timesteps {val_timesteps}\")\n",
        "        model = AdvancedGraphSAGE(\n",
        "            in_channels=self.input_dim,\n",
        "            hidden_channels=params[\"hidden_channels\"],\n",
        "            out_channels=2,\n",
        "            dropout=params[\"dropout\"],\n",
        "            residual=params[\"residual\"],\n",
        "            aggregation_methods=params[\"aggregation_methods\"],\n",
        "            edge_dropout=params[\"edge_dropout\"]\n",
        "        ).to(self.device)\n",
        "\n",
        "        param_device = next(model.parameters()).device\n",
        "        print(f\"Model parameter device: {param_device}\")\n",
        "        optimizer = torch.optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=params[\"learning_rate\"],\n",
        "            weight_decay=params[\"weight_decay\"]\n",
        "        )\n",
        "        class_weights = self.class_weights.clone()\n",
        "        class_weights[1] = class_weights[1] * params[\"class_weight_factor\"]\n",
        "\n",
        "        best_val_score = -float('inf')\n",
        "        patience = 8\n",
        "        patience_counter = 0\n",
        "\n",
        "        try:\n",
        "\n",
        "            for epoch in range(50):\n",
        "\n",
        "                model.train()\n",
        "                total_train_loss = 0.0\n",
        "                timesteps_processed = 0\n",
        "\n",
        "                for timestep in train_timesteps:\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "                    timestep_data = self.data_handler.process_timestep_with_sampling(\n",
        "                        self.df_edges,\n",
        "                        self.df_features,\n",
        "                        timestep,\n",
        "                        params[\"num_neighbors\"]\n",
        "                    ).to(self.device)\n",
        "\n",
        "                    valid_mask = (timestep_data.y != -1)\n",
        "                    if valid_mask.sum() == 0:\n",
        "                        del timestep_data\n",
        "                        continue\n",
        "                    optimizer.zero_grad()\n",
        "                    out = model(timestep_data.x, timestep_data.edge_index)\n",
        "\n",
        "                    loss = self.calculate_enhanced_loss(\n",
        "                        out[valid_mask],\n",
        "                        timestep_data.y[valid_mask],\n",
        "                        gamma=params[\"focal_gamma\"],\n",
        "                        label_smoothing=0.1,\n",
        "                        class_weights=class_weights\n",
        "                    )\n",
        "\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "                    total_train_loss += loss.item()\n",
        "                    timesteps_processed += 1\n",
        "\n",
        "                    del timestep_data, out, loss\n",
        "\n",
        "                avg_train_loss = total_train_loss / max(1, timesteps_processed)\n",
        "\n",
        "                model.eval()\n",
        "                val_metrics_by_timestep = []\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for val_timestep in val_timesteps:\n",
        "                        torch.cuda.empty_cache()\n",
        "                        val_data = self.data_handler.process_timestep_with_sampling(\n",
        "                            self.df_edges,\n",
        "                            self.df_features,\n",
        "                            val_timestep,\n",
        "                            params[\"num_neighbors\"]\n",
        "                        ).to(self.device)\n",
        "\n",
        "                        val_mask = (val_data.y != -1)\n",
        "                        if val_mask.sum() == 0:\n",
        "                            continue\n",
        "\n",
        "                        val_out = model(val_data.x, val_data.edge_index)\n",
        "                        val_probs = F.softmax(val_out[val_mask], dim=1)\n",
        "                        val_preds = val_probs.argmax(dim=1)\n",
        "\n",
        "                        y_val = val_data.y[val_mask].cpu().numpy()\n",
        "                        val_preds_np = val_preds.cpu().numpy()\n",
        "                        val_probs_np = val_probs.cpu().numpy()\n",
        "\n",
        "                        if len(np.unique(y_val)) > 1:\n",
        "                            timestep_metrics = self.calculate_metrics(y_val, val_preds_np, val_probs_np)\n",
        "                            val_metrics_by_timestep.append(timestep_metrics)\n",
        "\n",
        "                        del val_data, val_out, val_probs, val_preds\n",
        "\n",
        "                if val_metrics_by_timestep:\n",
        "                    avg_val_score = np.mean([\n",
        "                        metrics.get('composite_score', 0) for metrics in val_metrics_by_timestep\n",
        "                    ])\n",
        "\n",
        "                    if avg_val_score > best_val_score:\n",
        "                        best_val_score = avg_val_score\n",
        "                        patience_counter = 0\n",
        "                    else:\n",
        "                        patience_counter += 1\n",
        "\n",
        "                    if patience_counter >= patience:\n",
        "                        print(f\"Early stopping at epoch {epoch}\")\n",
        "                        break\n",
        "\n",
        "                    if epoch % 10 == 0:\n",
        "                        print(f\"Epoch {epoch}, train loss: {avg_train_loss:.4f}, val score: {avg_val_score:.4f}\")\n",
        "\n",
        "            print(f\"Best validation score: {best_val_score:.4f}\")\n",
        "            return best_val_score\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during trial: {str(e)}\")\n",
        "            return -float('inf')\n",
        "\n",
        "        del model, optimizer\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    def train_final_model_with_timesteps(self, best_params: Dict) -> Tuple[nn.Module, Dict]:\n",
        "        print(\"\\nTraining final model with best parameters...\")\n",
        "\n",
        "        num_layers = best_params[\"num_layers\"]\n",
        "        dropout = best_params[\"dropout\"]\n",
        "        learning_rate = best_params[\"learning_rate\"]\n",
        "        weight_decay = best_params[\"weight_decay\"]*2.0\n",
        "        residual = best_params[\"residual\"]\n",
        "        edge_dropout = best_params.get(\"edge_dropout\", 0.0)*1.5\n",
        "        focal_gamma = best_params.get(\"focal_gamma\", 2.0)\n",
        "        class_weight_factor = best_params.get(\"class_weight_factor\", 1.0)\n",
        "\n",
        "        hidden_channels = [best_params[f\"layer_{i}_channels\"] for i in range(num_layers)]\n",
        "        aggregation_methods = [best_params[f\"aggregation_layer_{i}\"] for i in range(num_layers)]\n",
        "        num_neighbors = [best_params[f\"neighbors_layer_{i}\"] for i in range(num_layers)]\n",
        "\n",
        "        all_timesteps = sorted(self.df_features['Time step'].unique())\n",
        "        train_timesteps = [ts for ts in all_timesteps if 1 <= ts <= 36]\n",
        "        val_timesteps = [ts for ts in all_timesteps if 37 <= ts <= 41]\n",
        "        test_timesteps = [ts for ts in all_timesteps if 42 <= ts <= 49]\n",
        "\n",
        "        print(f\"Using timesteps {train_timesteps} for training\")\n",
        "        print(f\"Using timesteps {val_timesteps} for validation/threshold optimization\")\n",
        "        print(f\"Using timesteps {test_timesteps} for final evaluation\")\n",
        "\n",
        "        model = AdvancedGraphSAGE(\n",
        "            in_channels=self.input_dim,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=2,\n",
        "            dropout=dropout,\n",
        "            residual=residual,\n",
        "            aggregation_methods=aggregation_methods,\n",
        "            edge_dropout=edge_dropout\n",
        "        ).to(self.device)\n",
        "\n",
        "        optimizer = torch.optim.Adam(\n",
        "            model.parameters(),\n",
        "            lr=learning_rate,\n",
        "            weight_decay=weight_decay\n",
        "        )\n",
        "\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='max', factor=0.5, patience=10, min_lr=1e-6, verbose=True\n",
        "        )\n",
        "\n",
        "        scaled_class_weights = self.class_weights.clone()\n",
        "        scaled_class_weights[1] = scaled_class_weights[1] * class_weight_factor\n",
        "\n",
        "        print(f\"\\nTraining with hyperparameters:\")\n",
        "        print(f\"  Learning rate: {learning_rate}\")\n",
        "        print(f\"  Weight decay: {weight_decay}\")\n",
        "        print(f\"  Edge dropout: {edge_dropout}\")\n",
        "        print(f\"  Focal gamma: {focal_gamma}\")\n",
        "        print(f\"  Class weight factor: {class_weight_factor}\")\n",
        "        print(f\"  Original class weights: {self.class_weights}\")\n",
        "        print(f\"  Scaled class weights: {scaled_class_weights}\")\n",
        "\n",
        "        model.optimal_class_weights = scaled_class_weights\n",
        "        model.optimal_gamma = focal_gamma\n",
        "\n",
        "\n",
        "        best_val_score = -float('inf')\n",
        "        best_model_state = None\n",
        "        patience = 15\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(200):\n",
        "\n",
        "            model.train()\n",
        "            total_train_loss = 0.0\n",
        "            timesteps_processed = 0\n",
        "\n",
        "            for timestep in train_timesteps:\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "                timestep_data = self.data_handler.process_timestep_with_sampling(\n",
        "                    self.df_edges,\n",
        "                    self.df_features,\n",
        "                    timestep,\n",
        "                    num_neighbors\n",
        "                ).to(self.device)\n",
        "\n",
        "                valid_mask = (timestep_data.y != -1)\n",
        "                if valid_mask.sum() == 0:\n",
        "                    continue\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Use edge weights if available\n",
        "                if hasattr(timestep_data, 'edge_weight'):\n",
        "                    out = model(timestep_data.x, timestep_data.edge_index, timestep_data.edge_weight)\n",
        "                else:\n",
        "                    out = model(timestep_data.x, timestep_data.edge_index)\n",
        "\n",
        "                # Use focal loss with tuned gamma parameter\n",
        "                loss = self.calculate_enhanced_loss(\n",
        "                    out[valid_mask],\n",
        "                    timestep_data.y[valid_mask],\n",
        "                    gamma=focal_gamma,\n",
        "                    label_smoothing=0.1,\n",
        "                    class_weights=scaled_class_weights\n",
        "                )\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "                timesteps_processed += 1\n",
        "                del timestep_data, out, loss\n",
        "\n",
        "            avg_train_loss = total_train_loss / max(1, timesteps_processed)\n",
        "\n",
        "            model.eval()\n",
        "            val_metrics_by_timestep = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for val_timestep in val_timesteps:\n",
        "                    torch.cuda.empty_cache()\n",
        "                    val_data = self.data_handler.process_timestep_with_sampling(\n",
        "                        self.df_edges,\n",
        "                        self.df_features,\n",
        "                        val_timestep,\n",
        "                        num_neighbors\n",
        "                    ).to(self.device)\n",
        "\n",
        "                    val_mask = (val_data.y != -1)\n",
        "                    if val_mask.sum() == 0:\n",
        "                        continue\n",
        "\n",
        "                    if hasattr(val_data, 'edge_weight'):\n",
        "                        val_out = model(val_data.x, val_data.edge_index, val_data.edge_weight)\n",
        "                    else:\n",
        "                        val_out = model(val_data.x, val_data.edge_index)\n",
        "\n",
        "                    val_out = val_out[val_mask]\n",
        "                    val_probs = F.softmax(val_out, dim=1)\n",
        "                    val_preds = val_probs.argmax(dim=1)\n",
        "\n",
        "                    y_val = val_data.y[val_mask].cpu().numpy()\n",
        "                    val_preds_np = val_preds.cpu().numpy()\n",
        "                    val_probs_np = val_probs.cpu().numpy()\n",
        "\n",
        "                    if len(np.unique(y_val)) > 1:\n",
        "                        timestep_metrics = self.calculate_metrics(y_val, val_preds_np, val_probs_np)\n",
        "                        val_metrics_by_timestep.append(timestep_metrics)\n",
        "                    del val_data, val_out, val_probs, val_preds\n",
        "\n",
        "            if val_metrics_by_timestep:\n",
        "                avg_composite_score = np.mean([\n",
        "                    metrics.get('composite_score', 0) for metrics in val_metrics_by_timestep\n",
        "                ])\n",
        "\n",
        "                if avg_composite_score > best_val_score:\n",
        "                    best_val_score = avg_composite_score\n",
        "                    best_model_state = copy.deepcopy(model.state_dict())\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                scheduler.step(avg_composite_score)\n",
        "\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping at epoch {epoch}\")\n",
        "                    break\n",
        "\n",
        "                if epoch % 5 == 0:\n",
        "                    avg_metrics = {\n",
        "                        k: np.mean([m.get(k, 0) for m in val_metrics_by_timestep])\n",
        "                        for k in val_metrics_by_timestep[0].keys()\n",
        "                        if k != 'confusion_matrix'\n",
        "                    }\n",
        "                    print(f\"Epoch {epoch}: Avg Train Loss = {avg_train_loss:.4f}, Val Score = {avg_composite_score:.4f}\")\n",
        "                    for k, v in avg_metrics.items():\n",
        "                        if k in ['composite_score', 'class_1_recall', 'class_1_precision', 'class_1_f1']:\n",
        "                            print(f\"  {k}: {v:.4f}\")\n",
        "\n",
        "                    if self.wandb_run is not None:\n",
        "                        log_dict = {\n",
        "                            'epoch': epoch,\n",
        "                            'train_loss': avg_train_loss,\n",
        "                            'val_composite_score': avg_composite_score,\n",
        "                            **{f'val_{k}': v for k, v in avg_metrics.items()}\n",
        "                        }\n",
        "                        self.wandb_run.log(log_dict)\n",
        "\n",
        "        print(\"\\nLoading best model state from training\")\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "\n",
        "        print(\"\\n=== Finding Optimal Classification Threshold ===\")\n",
        "        val_probs_all = []\n",
        "        val_true_all = []\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_timestep in val_timesteps:\n",
        "                torch.cuda.empty_cache()\n",
        "                val_data = self.data_handler.process_timestep_with_sampling(\n",
        "                    self.df_edges,\n",
        "                    self.df_features,\n",
        "                    val_timestep,\n",
        "                    num_neighbors\n",
        "                ).to(self.device)\n",
        "\n",
        "                val_mask = (val_data.y != -1)\n",
        "                if val_mask.sum() == 0:\n",
        "                    continue\n",
        "\n",
        "                if hasattr(val_data, 'edge_weight'):\n",
        "                    val_out = model(val_data.x, val_data.edge_index, val_data.edge_weight)\n",
        "                else:\n",
        "                    val_out = model(val_data.x, val_data.edge_index)\n",
        "\n",
        "                val_probs = F.softmax(val_out[val_mask], dim=1)\n",
        "                val_true_all.append(val_data.y[val_mask].cpu().numpy())\n",
        "                val_probs_all.append(val_probs.cpu().numpy())\n",
        "                del val_data, val_out, val_probs\n",
        "\n",
        "        if val_probs_all and len(val_probs_all) > 0:\n",
        "            val_probs_combined = np.vstack(val_probs_all)\n",
        "            val_true_combined = np.concatenate(val_true_all)\n",
        "            optimal_threshold = self.find_optimal_threshold(val_true_combined, val_probs_combined[:, 1])\n",
        "            print(f\"\\nOptimal threshold found: {optimal_threshold:.4f}\")\n",
        "        else:\n",
        "            optimal_threshold = 0.5\n",
        "            print(\"\\nUsing default threshold: 0.5 (no valid validation data)\")\n",
        "\n",
        "        model.optimal_threshold = optimal_threshold\n",
        "\n",
        "        print(\"\\n=== Evaluating Model Performance Per Timestep Starting from 37 (Using Adjusted Threshold) ===\")\n",
        "\n",
        "        val_timesteps = [ts for ts in self.df_features['Time step'].unique() if 37 <= ts <= 41]\n",
        "        test_timesteps = [ts for ts in self.df_features['Time step'].unique() if 42 <= ts <= 49]\n",
        "        all_eval_timesteps = sorted(val_timesteps + test_timesteps)\n",
        "\n",
        "        test_timestep_results = {}\n",
        "        for eval_timestep in all_eval_timesteps:\n",
        "            print(f\"\\nEvaluating on timestep {eval_timestep}:\")\n",
        "\n",
        "            timestep_type = \"validation\" if eval_timestep <= 41 else \"test\"\n",
        "            print(f\"  Timestep type: {timestep_type}\")\n",
        "r\n",
        "            timestep_data = self.data_handler.process_timestep_with_sampling(\n",
        "                self.df_edges,\n",
        "                self.df_features,\n",
        "                eval_timestep,\n",
        "                num_neighbors\n",
        "            ).to(self.device)\n",
        "\n",
        "            valid_mask = (timestep_data.y != -1)\n",
        "            if valid_mask.sum() == 0:\n",
        "                print(f\"  No valid nodes for timestep {eval_timestep}\")\n",
        "                continue\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                out = model(timestep_data.x, timestep_data.edge_index)\n",
        "                out_valid = out[valid_mask]\n",
        "                probs = F.softmax(out_valid, dim=1)\n",
        "\n",
        "                y_true = timestep_data.y[valid_mask].cpu().numpy()\n",
        "                probs_np = probs.cpu().numpy()\n",
        "\n",
        "                preds_np = (probs_np[:, 1] >= optimal_threshold).astype(int)\n",
        "\n",
        "                try:\n",
        "\n",
        "                    test_metrics = self.calculate_metrics(y_true, preds_np, probs_np)\n",
        "                    test_timestep_results[eval_timestep] = test_metrics\n",
        "\n",
        "\n",
        "                    print(f\"  Composite Score: {test_metrics.get('composite_score', 0):.4f}\")\n",
        "                    print(f\"  Class 1 Recall: {test_metrics.get('class_1_recall', 0):.4f}\")\n",
        "                    print(f\"  Class 1 F1: {test_metrics.get('class_1_f1', 0):.4f}\")\n",
        "                    print(f\"  Class 0 Recall: {test_metrics.get('class_0_recall', 0):.4f}\")\n",
        "                    print(f\"  Class 0 F1: {test_metrics.get('class_0_f1', 0):.4f}\")\n",
        "                    print(f\"  Balanced Acc: {test_metrics.get('balanced_accuracy', 0):.4f}\")\n",
        "                    print(f\"  Precision: {test_metrics.get('precision', 0):.4f}\")\n",
        "                    print(f\"  MCC: {test_metrics.get('mcc', 0):.4f}\")\n",
        "                    print(f\"  PR-AUC: {test_metrics.get('pr_auc', 0):.4f}\")\n",
        "                    print(f\"  ROC-AUC: {test_metrics.get('auroc', 0):.4f}\")\n",
        "\n",
        "                    if self.wandb_run is not None:\n",
        "                        self.wandb_run.log({\n",
        "                            f\"timestep_{eval_timestep}_composite_score\": test_metrics.get('composite_score', 0),\n",
        "                            f\"timestep_{eval_timestep}_recall_1\": test_metrics.get('class_1_recall', 0),\n",
        "                            f\"timestep_{eval_timestep}_f1_1\": test_metrics.get('class_1_f1', 0),\n",
        "                            f\"timestep_{eval_timestep}_recall_0\": test_metrics.get('class_0_recall', 0),\n",
        "                            f\"timestep_{eval_timestep}_f1_0\": test_metrics.get('class_0_f1', 0),\n",
        "                            f\"timestep_{eval_timestep}_balanced_acc\": test_metrics.get('balanced_accuracy', 0),\n",
        "                            f\"timestep_{eval_timestep}_precision\": test_metrics.get('precision', 0),\n",
        "                            f\"timestep_{eval_timestep}_mcc\": test_metrics.get('mcc', 0),\n",
        "                            f\"timestep_{eval_timestep}_pr_auc\": test_metrics.get('pr_auc', 0),\n",
        "                            f\"timestep_{eval_timestep}_roc_auc\": test_metrics.get('auroc', 0)\n",
        "                        })\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error calculating metrics: {str(e)}\")\n",
        "                    print(f\"  Debug - y_true shape: {y_true.shape}, preds_np shape: {preds_np.shape}\")\n",
        "                    print(f\"  Debug - probs_np shape: {probs_np.shape}\")\n",
        "                    print(f\"  Debug - unique values in y_true: {np.unique(y_true)}\")\n",
        "                    print(f\"  Debug - unique values in preds_np: {np.unique(preds_np)}\")\n",
        "\n",
        "        print(\"\\n=== Final Evaluation on Test Set (Default Threshold) ===\")\n",
        "        test_metrics_default = self.evaluate_model_on_data(\n",
        "            model=model,\n",
        "            timesteps=test_timesteps,\n",
        "            num_neighbors=num_neighbors,\n",
        "            threshold=0.5\n",
        "        )\n",
        "\n",
        "        if test_metrics_default:\n",
        "            print(\"Final Test Metrics (Default Threshold):\")\n",
        "            for metric, value in test_metrics_default.items():\n",
        "                if metric != 'combined_metrics' and metric != 'confusion_matrix':\n",
        "                    print(f\"{metric}: {value:.4f}\")\n",
        "                elif metric == 'confusion_matrix':\n",
        "                    print(f\"{metric}: {value}\")\n",
        "\n",
        "        print(f\"\\nFinal Test Metrics (Adjusted Threshold = {optimal_threshold:.4f}):\")\n",
        "        test_metrics_adjusted = self.evaluate_model_on_data(\n",
        "            model=model,\n",
        "            timesteps=test_timesteps,\n",
        "            num_neighbors=num_neighbors,\n",
        "            threshold=optimal_threshold\n",
        "        )\n",
        "\n",
        "        if test_metrics_adjusted:\n",
        "            for metric, value in test_metrics_adjusted.items():\n",
        "                if metric != 'combined_metrics' and metric != 'confusion_matrix':\n",
        "                    print(f\"{metric}: {value:.4f}\")\n",
        "                elif metric == 'confusion_matrix':\n",
        "                    print(f\"{metric}: {value}\")\n",
        "\n",
        "        print(\"\\nThreshold Adjustment Impact:\")\n",
        "        if test_metrics_default and test_metrics_adjusted:\n",
        "            for metric in test_metrics_default.keys():\n",
        "                if metric != 'combined_metrics' and metric != 'confusion_matrix':\n",
        "                    default_val = test_metrics_default.get(metric, 0)\n",
        "                    adjusted_val = test_metrics_adjusted.get(metric, 0)\n",
        "                    diff = adjusted_val - default_val\n",
        "                    print(f\"{metric}: {diff:.4f} ({'improvement' if diff > 0 else 'decrease'})\")\n",
        "\n",
        "        if self.wandb_run is not None:\n",
        "            self.wandb_run.log({\n",
        "                **{f'test_default_{k}': v for k, v in test_metrics_default.items()\n",
        "                  if k != 'combined_metrics' and k != 'confusion_matrix'},\n",
        "                **{f'test_adjusted_{k}': v for k, v in test_metrics_adjusted.items()\n",
        "                  if k != 'combined_metrics' and k != 'confusion_matrix'},\n",
        "                'optimal_threshold': optimal_threshold\n",
        "            })\n",
        "\n",
        "        return model, {\n",
        "            'val_score': best_val_score,\n",
        "            'optimal_threshold': optimal_threshold,\n",
        "            'timestep_results': test_timestep_results,\n",
        "            'test_metrics_default': test_metrics_default,\n",
        "            'test_metrics_adjusted': test_metrics_adjusted\n",
        "        }\n",
        "\n",
        "    def evaluate_model_on_data(self, model, timesteps, num_neighbors, threshold=0.5):\n",
        "        model.eval()\n",
        "        metrics_by_timestep = []\n",
        "        all_true = []\n",
        "        all_pred = []\n",
        "        all_probs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for timestep in timesteps:\n",
        "                torch.cuda.empty_cache()\n",
        "                data = self.data_handler.process_timestep_with_sampling(\n",
        "                    self.df_edges,\n",
        "                    self.df_features,\n",
        "                    timestep,\n",
        "                    num_neighbors\n",
        "                ).to(self.device)\n",
        "\n",
        "                valid_mask = (data.y != -1)\n",
        "                if valid_mask.sum() == 0:\n",
        "                    continue\n",
        "\n",
        "                if hasattr(data, 'edge_weight'):\n",
        "                    out = model(data.x, data.edge_index, data.edge_weight)\n",
        "                else:\n",
        "                    out = model(data.x, data.edge_index)\n",
        "\n",
        "                probs = F.softmax(out[valid_mask], dim=1)\n",
        "                preds = (probs[:, 1] >= threshold).long()\n",
        "\n",
        "                y_true = data.y[valid_mask].cpu().numpy()\n",
        "                preds_np = preds.cpu().numpy()\n",
        "                probs_np = probs.cpu().numpy()\n",
        "\n",
        "                all_true.append(y_true)\n",
        "                all_pred.append(preds_np)\n",
        "                all_probs.append(probs_np)\n",
        "\n",
        "                if len(np.unique(y_true)) > 1:\n",
        "                    metrics = self.calculate_metrics(y_true, preds_np, probs_np)\n",
        "                    metrics['timestep'] = timestep\n",
        "                    metrics_by_timestep.append(metrics)\n",
        "\n",
        "        if metrics_by_timestep:\n",
        "            avg_metrics = {\n",
        "                k: np.mean([m.get(k, 0) for m in metrics_by_timestep])\n",
        "                for k in metrics_by_timestep[0].keys()\n",
        "                if k != 'timestep' and k != 'confusion_matrix'\n",
        "            }\n",
        "\n",
        "            if all_true and all_pred and all_probs:\n",
        "                combined_true = np.concatenate(all_true)\n",
        "                combined_pred = np.concatenate(all_pred)\n",
        "                combined_probs = np.vstack(all_probs)\n",
        "\n",
        "                combined_metrics = self.calculate_metrics(combined_true, combined_pred, combined_probs)\n",
        "                avg_metrics['combined_metrics'] = combined_metrics\n",
        "\n",
        "            return avg_metrics\n",
        "        else:\n",
        "            return {}\n",
        "\n",
        "    def calculate_enhanced_loss(self, outputs, targets, gamma=2.0,\n",
        "                              label_smoothing=0.1, class_weights=None):\n",
        "        # Apply label smoothing\n",
        "        num_classes = outputs.size(-1)\n",
        "        smooth_targets = torch.zeros_like(outputs)\n",
        "        smooth_targets.fill_(label_smoothing / (num_classes - 1))\n",
        "        smooth_targets.scatter_(1, targets.unsqueeze(1), 1 - label_smoothing)\n",
        "\n",
        "        # Calculate focal loss\n",
        "        probs = F.softmax(outputs, dim=-1)\n",
        "        focal_weight = (1 - probs) ** gamma\n",
        "\n",
        "        loss = -(focal_weight * smooth_targets * torch.log(probs + 1e-8))\n",
        "        loss = loss.sum(dim=1)\n",
        "\n",
        "        if class_weights is not None:\n",
        "            class_weights = class_weights.to(outputs.device)\n",
        "            weight_per_sample = class_weights[targets]\n",
        "            loss = loss * weight_per_sample\n",
        "\n",
        "        return loss.mean()\n",
        "\n",
        "    def run_parameter_search(self, n_trials: int = 50) -> Dict:\n",
        "\n",
        "        study = optuna.create_study(\n",
        "            direction=\"maximize\",\n",
        "            pruner=optuna.pruners.HyperbandPruner(\n",
        "                min_resource=5,\n",
        "                max_resource=50,\n",
        "                reduction_factor=3\n",
        "            )\n",
        "        )\n",
        "        study.optimize(self._objective, n_trials=n_trials)\n",
        "\n",
        "        print(\"\\nBest parameters found:\")\n",
        "        for param, value in study.best_params.items():\n",
        "            print(f\"{param}: {value}\")\n",
        "\n",
        "        if self.wandb_run is not None:\n",
        "            self.wandb_run.log({\n",
        "                \"best_params\": study.best_params,\n",
        "                \"hyperparameter_search\": \"fixed_validation_set\"\n",
        "            })\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "\n",
        "    def cleanup(self):\n",
        "        \"\"\"Cleanup resources\"\"\"\n",
        "        if self.wandb_run is not None:\n",
        "            try:\n",
        "                self.wandb_run.finish()\n",
        "            except:\n",
        "                pass\n",
        "            self.wandb_run = None\n",
        "\n"
      ],
      "metadata": {
        "id": "m7gwkhWjHqyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6G3FDKEVRARi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edbb94c8-783f-43ee-dc17-aefb980a6833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/My Drive'\n",
        "save_path = '/content/drive/My Drive'\n",
        "files = os.listdir(data_path)\n",
        "print(files)"
      ],
      "metadata": {
        "id": "6miNmQXHV0Zm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412654ad-9536-4e13-ec71-cd1a0d35f58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Colab Notebooks', 'AddrAddr_edgelist.csv', 'wallets_features_classes_combined.csv', 'processed_dataset_with_network.csv', 'processed_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHandler:\n",
        "\n",
        "    def __init__(self, checkpoint_dir: str, device=None):\n",
        "        self.checkpoint_dir = Path(checkpoint_dir)\n",
        "        self.node_maps = {}\n",
        "        self.edge_indices = {}\n",
        "        self.data_cache = {}\n",
        "        self.oversampled_data_cache = {}\n",
        "        self.cache_hits = 0\n",
        "        self.cache_misses = 0\n",
        "\n",
        "        self.device = device if device is not None else torch.device('cpu')\n",
        "\n",
        "    def process_timestep_with_oversampling(self, df_edges: pd.DataFrame, df_features: pd.DataFrame,\n",
        "                                         timestep: int, num_neighbors: List[int],\n",
        "                                         oversample_ratio: float = 30.0) -> Data:\n",
        "\n",
        "        cache_key = f\"oversample_ts{timestep}_ratio{oversample_ratio}_nn{hash(str(num_neighbors))}\"\n",
        "        if cache_key in self.oversampled_data_cache:\n",
        "\n",
        "            self.cache_hits += 1\n",
        "            cached_data = self.oversampled_data_cache[cache_key]\n",
        "            if self.cache_hits % 50 == 0:\n",
        "                print(f\"Cache hit: {cache_key} (hits: {self.cache_hits}, misses: {self.cache_misses})\")\n",
        "            return cached_data.to(self.device)\n",
        "\n",
        "        self.cache_misses += 1\n",
        "        if self.cache_misses % 10 == 0:\n",
        "            print(f\"Cache miss: {cache_key} (hits: {self.cache_hits}, misses: {self.cache_misses})\")\n",
        "\n",
        "        data = self.process_timestep_with_sampling(df_edges, df_features, timestep, num_neighbors)\n",
        "        if timestep < 1 or timestep > 36:\n",
        "            return data\n",
        "\n",
        "        valid_mask = (data.y != -1)\n",
        "        if valid_mask.sum() > 0:\n",
        "            try:\n",
        "\n",
        "                valid_labels = data.y[valid_mask].cpu()\n",
        "                class_counts = torch.bincount(valid_labels)\n",
        "\n",
        "                if len(class_counts) > 1 and class_counts[1] > 0:\n",
        "                    majority_count = class_counts[0].item()\n",
        "                    minority_count = class_counts[1].item()\n",
        "                    target_minority = int(min(minority_count * oversample_ratio, majority_count))\n",
        "                    n_synthetic = max(0, target_minority - minority_count)\n",
        "\n",
        "                    if n_synthetic > 0:\n",
        "                        print(f\"Timestep {timestep}: Oversampling minority class. Original: {minority_count}, Target: {target_minority}\")\n",
        "\n",
        "                        new_x, new_edge_index, new_y = graph_smote(\n",
        "                            data.x, data.edge_index, data.y,\n",
        "                            minority_class=1,\n",
        "                            k_neighbors=5,\n",
        "                            n_synthetic=n_synthetic\n",
        "                        )\n",
        "\n",
        "                        if new_x.size(0) > data.x.size(0):\n",
        "                            new_nodes_count = new_x.size(0) - data.x.size(0)\n",
        "                            new_time_steps = torch.full(\n",
        "                                (new_nodes_count,), timestep,\n",
        "                                dtype=torch.long, device=data.time_step.device\n",
        "                            )\n",
        "                            new_time_step = torch.cat([data.time_step, new_time_steps])\n",
        "\n",
        "                            if hasattr(data, 'original_indices'):\n",
        "                                synthetic_indices = torch.full(\n",
        "                                    (new_nodes_count,), -1,\n",
        "                                    dtype=data.original_indices.dtype,\n",
        "                                    device=data.original_indices.device\n",
        "                                )\n",
        "                                new_original_indices = torch.cat([data.original_indices, synthetic_indices])\n",
        "                            else:\n",
        "                                new_original_indices = None\n",
        "\n",
        "                            data = Data(\n",
        "                                x=new_x,\n",
        "                                edge_index=new_edge_index,\n",
        "                                y=new_y,\n",
        "                                time_step=new_time_step,\n",
        "                                original_indices=new_original_indices if hasattr(data, 'original_indices') else None\n",
        "                            )\n",
        "\n",
        "                            data.edge_weight = weight_minority_edges(\n",
        "                                data.edge_index, data.y,\n",
        "                                minority_class=1, weight_factor=2.0\n",
        "                            )\n",
        "\n",
        "                            print(f\"  Created {new_nodes_count} synthetic nodes.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error in oversampling timestep {timestep}: {str(e)}\")\n",
        "\n",
        "        self.oversampled_data_cache[cache_key] = data.cpu()\n",
        "        return data.to(self.device)\n",
        "\n",
        "    def get_cache_stats(self):\n",
        "        total_calls = self.cache_hits + self.cache_misses\n",
        "        hit_rate = self.cache_hits / total_calls if total_calls > 0 else 0\n",
        "\n",
        "        return {\n",
        "            \"hits\": self.cache_hits,\n",
        "            \"misses\": self.cache_misses,\n",
        "            \"total_calls\": total_calls,\n",
        "            \"hit_rate\": hit_rate,\n",
        "            \"oversampled_entries\": len(self.oversampled_data_cache),\n",
        "            \"standard_entries\": len(self.data_cache)\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess_with_smote(df_features, df_edges, oversample_ratio=30.0, start_timestep=1, end_timestep=35):\n",
        "\n",
        "        print(f\"\\n=== Preprocessing with GraphSMOTE (Timesteps {start_timestep}-{end_timestep}) ===\")\n",
        "        features_df = df_features.copy()\n",
        "        edges_df = df_edges.copy()\n",
        "        max_node_id = features_df['node_id'].max()\n",
        "        if isinstance(max_node_id, str):\n",
        "            max_node_id = max([int(nid.split('_')[-1]) if '_' in nid else 0\n",
        "                              for nid in features_df['node_id']])\n",
        "        next_node_id = max_node_id + 1\n",
        "        new_nodes = []\n",
        "        new_edges = []\n",
        "        all_timesteps = sorted(features_df['Time step'].unique())\n",
        "        allowed_timesteps = [ts for ts in all_timesteps if start_timestep <= ts <= end_timestep]\n",
        "\n",
        "        print(f\"Will only process timesteps: {allowed_timesteps}\")\n",
        "\n",
        "        for timestep in allowed_timesteps:\n",
        "            timestep_features = features_df[features_df['Time step'] == timestep]\n",
        "            if 'binary_class' in timestep_features.columns:\n",
        "                minority_nodes = timestep_features[timestep_features['binary_class'] == 1]\n",
        "                majority_nodes = timestep_features[timestep_features['binary_class'] == 0]\n",
        "            else:\n",
        "                minority_nodes = timestep_features[timestep_features['class'] == 1]\n",
        "                majority_nodes = timestep_features[timestep_features['class'] == 2]d\n",
        "            if len(minority_nodes) == 0 or len(minority_nodes) >= len(majority_nodes):\n",
        "                print(f\"Timestep {timestep}: Skipping (minority: {len(minority_nodes)}, majority: {len(majority_nodes)})\")\n",
        "                continue\n",
        "\n",
        "            target_samples = min(int(len(minority_nodes) * oversample_ratio), len(majority_nodes))\n",
        "            samples_to_generate = max(0, target_samples - len(minority_nodes))\n",
        "\n",
        "            print(f\"Timestep {timestep}: Oversampling minority class. Original: {len(minority_nodes)}, Target: {target_samples}\")\n",
        "\n",
        "            if samples_to_generate == 0:\n",
        "                continue\n",
        "\n",
        "            node_to_idx = {node: idx for idx, node in enumerate(timestep_features['node_id'])}\n",
        "            idx_to_node = {idx: node for node, idx in node_to_idx.items()}\n",
        "\n",
        "            feature_cols = timestep_features.columns.difference(['node_id', 'Time step', 'class', 'binary_class'])\n",
        "            X = torch.tensor(timestep_features[feature_cols].values, dtype=torch.float32)\n",
        "            if 'binary_class' in timestep_features.columns:\n",
        "                y = torch.tensor(timestep_features['binary_class'].values, dtype=torch.long)\n",
        "            else:\n",
        "                y = torch.tensor(timestep_features['class'].map(lambda x: 1 if x == 1 else (0 if x == 2 else -1)).values,\n",
        "                                dtype=torch.long)\n",
        "\n",
        "            timestep_edges = edges_df[\n",
        "                edges_df['source'].isin(timestep_features['node_id']) &\n",
        "                edges_df['target'].isin(timestep_features['node_id'])\n",
        "            ]\n",
        "\n",
        "            edge_index = []\n",
        "            for _, edge in timestep_edges.iterrows():\n",
        "                if edge['source'] in node_to_idx and edge['target'] in node_to_idx:\n",
        "                    edge_index.append([node_to_idx[edge['source']], node_to_idx[edge['target']]])\n",
        "\n",
        "            edge_index = torch.tensor(edge_index, dtype=torch.long).t() if edge_index else torch.zeros((2, 0), dtype=torch.long)\n",
        "\n",
        "            try:\n",
        "                new_X, new_edge_index, new_y = graph_smote(\n",
        "                    X, edge_index, y,\n",
        "                    minority_class=1,\n",
        "                    k_neighbors=5,\n",
        "                    n_synthetic=samples_to_generate\n",
        "                )\n",
        "\n",
        "                num_original_nodes = X.size(0)\n",
        "                num_synthetic_nodes = new_X.size(0) - num_original_nodes\n",
        "\n",
        "                if num_synthetic_nodes > 0:\n",
        "                    print(f\"  Created {num_synthetic_nodes} synthetic nodes.\")\n",
        "\n",
        "                    for i in range(num_original_nodes, new_X.size(0)):\n",
        "                        if isinstance(max_node_id, str):\n",
        "                            new_id = f\"synthetic_{next_node_id}\"\n",
        "                        else:\n",
        "                            new_id = f\"synthetic_{next_node_id}\"\n",
        "                        next_node_id += 1\n",
        "                        node_data = {\n",
        "                            'node_id': new_id,\n",
        "                            'Time step': timestep,\n",
        "                            'binary_class': new_y[i].item(),\n",
        "                            'class': 1 if new_y[i].item() == 1 else 2,\n",
        "                            **{col: new_X[i, j].item() for j, col in enumerate(feature_cols)}\n",
        "                        }\n",
        "                        new_nodes.append(node_data)\n",
        "                        idx_to_node[i] = new_id\n",
        "\n",
        "                    for j in range(new_edge_index.size(1)):\n",
        "                        src_idx, dst_idx = new_edge_index[0, j].item(), new_edge_index[1, j].item()\n",
        "\n",
        "                        if src_idx >= num_original_nodes or dst_idx >= num_original_nodes:\n",
        "                            if src_idx in idx_to_node and dst_idx in idx_to_node:\n",
        "                                new_edges.append({\n",
        "                                    'source': idx_to_node[src_idx],\n",
        "                                    'target': idx_to_node[dst_idx]\n",
        "                                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in GraphSMOTE for timestep {timestep}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if new_nodes:\n",
        "            synthetic_nodes_df = pd.DataFrame(new_nodes)\n",
        "            oversampled_features = pd.concat([features_df, synthetic_nodes_df], ignore_index=True)\n",
        "            print(f\"Added {len(synthetic_nodes_df)} synthetic nodes to features DataFrame.\")\n",
        "        else:\n",
        "            oversampled_features = features_df\n",
        "            print(\"No synthetic nodes were added.\")\n",
        "\n",
        "\n",
        "        if new_edges:\n",
        "            synthetic_edges_df = pd.DataFrame(new_edges)\n",
        "            oversampled_edges = pd.concat([edges_df, synthetic_edges_df], ignore_index=True)\n",
        "            print(f\"Added {len(synthetic_edges_df)} synthetic edges to edges DataFrame.\")\n",
        "        else:\n",
        "            oversampled_edges = edges_df\n",
        "            print(\"No synthetic edges were added.\")\n",
        "\n",
        "        if 'binary_class' in oversampled_features.columns:\n",
        "            print(\"\\nClass distribution after oversampling:\")\n",
        "            print(oversampled_features['binary_class'].value_counts().sort_index())\n",
        "        else:\n",
        "            print(\"\\nClass distribution after oversampling:\")\n",
        "            print(oversampled_features['class'].value_counts().sort_index())\n",
        "\n",
        "        print(\"\\n=== Summary of GraphSMOTE Preprocessing ===\")\n",
        "        print(f\"Only processed timesteps {start_timestep} to {end_timestep}\")\n",
        "        if new_nodes:\n",
        "            print(f\"Total synthetic nodes added: {len(new_nodes)}\")\n",
        "        if new_edges:\n",
        "            print(f\"Total synthetic edges added: {len(new_edges)}\")\n",
        "\n",
        "        return oversampled_features, oversampled_edges\n",
        "\n",
        "    def load_preprocessed_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
        "        df_features = pd.read_parquet(self.checkpoint_dir / 'processed_features.parquet')\n",
        "        df_edges = pd.read_parquet(self.checkpoint_dir / 'processed_edges.parquet')\n",
        "\n",
        "        df_features['node_id'] = df_features['node_id'].astype(str)\n",
        "        df_edges['source'] = df_edges['source'].astype(str)\n",
        "        df_edges['target'] = df_edges['target'].astype(str)\n",
        "\n",
        "        self.valid_nodes = set(df_features['node_id'])\n",
        "\n",
        "        return df_edges, df_features\n",
        "\n",
        "    def process_timestep_with_sampling(self, df_edges: pd.DataFrame, df_features: pd.DataFrame,\n",
        "                                    timestep: int, num_neighbors: List[int]) -> Data:\n",
        "\n",
        "        cache_key = f\"timestep_{timestep}_{hash(str(num_neighbors))}\"\n",
        "        if cache_key in self.data_cache:\n",
        "            cached_data = self.data_cache[cache_key]\n",
        "            return cached_data.to(self.device)\n",
        "        current_features = df_features[df_features['Time step'] == timestep]\n",
        "        if timestep not in self.node_maps:\n",
        "            self.node_maps[timestep] = {node: idx for idx, node in enumerate(current_features['node_id'])}\n",
        "        node_map = self.node_maps[timestep]\n",
        "\n",
        "        feature_cols = current_features.columns.difference(['node_id', 'Time step', 'class', 'binary_class'])\n",
        "        x = torch.tensor(current_features[feature_cols].values, dtype=torch.float32)\n",
        "\n",
        "        if timestep not in self.edge_indices:\n",
        "            self.edge_indices[timestep] = self._create_edge_index(df_edges, node_map)\n",
        "        edge_index = self.edge_indices[timestep]\n",
        "\n",
        "        if 'binary_class' in current_features.columns:\n",
        "            y = torch.tensor(current_features['binary_class'].values, dtype=torch.long)\n",
        "        else:\n",
        "            y = torch.tensor(current_features['class'].values, dtype=torch.long)\n",
        "\n",
        "        data = Data(\n",
        "            x=x.to(self.device),\n",
        "            edge_index=edge_index.to(self.device),\n",
        "            y=y.to(self.device),\n",
        "            time_step=torch.full((len(x),), timestep, dtype=torch.long).to(self.device),\n",
        "            original_indices=torch.arange(len(current_features)).to(self.device)\n",
        "        )\n",
        "\n",
        "        subgraph_loader = NeighborLoader(\n",
        "            data,\n",
        "            num_neighbors=num_neighbors,\n",
        "            batch_size=len(data.x),\n",
        "            shuffle=True,\n",
        "            directed=True\n",
        "        )\n",
        "\n",
        "        batch = next(iter(subgraph_loader))\n",
        "\n",
        "        return batch\n",
        "\n",
        "    def _create_edge_index(self, df_edges: pd.DataFrame, node_map: Dict) -> torch.Tensor:\n",
        "        valid_nodes_subset = set(node_map.keys())\n",
        "\n",
        "        valid_source = df_edges['source'].isin(valid_nodes_subset)\n",
        "        valid_target = df_edges['target'].isin(valid_nodes_subset)\n",
        "        mask = valid_source & valid_target\n",
        "        valid_edges = df_edges[mask]\n",
        "\n",
        "        src_indices = [node_map[src] for src in valid_edges['source']]\n",
        "        dst_indices = [node_map[dst] for dst in valid_edges['target']]\n",
        "\n",
        "        edge_index = torch.tensor([src_indices, dst_indices], dtype=torch.long)\n",
        "\n",
        "        return edge_index\n",
        "\n"
      ],
      "metadata": {
        "id": "NSSr6YW7su9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MetricsVisualizer:\n",
        "    def __init__(self, wandb_run=None):\n",
        "        self.wandb_run = wandb_run\n",
        "\n",
        "    def plot_confusion_matrix(self, y_true: np.ndarray, y_pred: np.ndarray, title: str) -> plt.Figure:\n",
        "        cm = confusion_matrix(y_true, y_pred)\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap='Blues')\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_title(title)\n",
        "        return fig\n",
        "\n",
        "    def plot_pr_curve(self, y_true: np.ndarray, y_prob: np.ndarray, title: str) -> plt.Figure:\n",
        "        precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
        "        pr_auc = auc(recall, precision)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(8, 6))\n",
        "        ax.plot(recall, precision, label=f'PR-AUC: {pr_auc:.3f}')\n",
        "        ax.set_xlabel('Recall')\n",
        "        ax.set_ylabel('Precision')\n",
        "        ax.set_title(title)\n",
        "        ax.legend()\n",
        "        return fig\n",
        "\n",
        "    def log_visualizations(self, y_true: np.ndarray, y_pred: np.ndarray,\n",
        "                          y_prob: np.ndarray, prefix: str = ''):\n",
        "        if self.wandb_run is not None:\n",
        "            cm_fig = self.plot_confusion_matrix(y_true, y_pred, f'{prefix} Confusion Matrix')\n",
        "            pr_fig = self.plot_pr_curve(y_true, y_prob, f'{prefix} Precision-Recall Curve')\n",
        "\n",
        "            self.wandb_run.log({\n",
        "                f'{prefix}_confusion_matrix': wandb.Image(cm_fig),\n",
        "                f'{prefix}_pr_curve': wandb.Image(pr_fig)\n",
        "            })\n",
        "\n",
        "            plt.close(cm_fig)\n",
        "            plt.close(pr_fig)"
      ],
      "metadata": {
        "id": "unzABMP_1WLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdvancedGraphSAGE(nn.Module):\n",
        "    def __init__(self, in_channels: int, hidden_channels: List[int], out_channels: int,\n",
        "                 dropout: float = 0.5, residual: bool = True,\n",
        "                 aggregation_methods: List[str] = None, edge_dropout: float = 0.0):\n",
        "        super().__init__()\n",
        "        self.num_layers = len(hidden_channels)\n",
        "        self.residual = residual\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.dropout_rate = dropout\n",
        "        self.edge_dropout_rate = edge_dropout\n",
        "\n",
        "        if aggregation_methods is None:\n",
        "            aggregation_methods = ['mean'] * self.num_layers\n",
        "\n",
        "        self.layers = nn.ModuleList([\n",
        "            CustomSAGEConv(in_channels, hidden_channels[0], aggr=aggregation_methods[0])\n",
        "        ])\n",
        "\n",
        "        for i in range(1, self.num_layers):\n",
        "            self.layers.append(\n",
        "                CustomSAGEConv(\n",
        "                    hidden_channels[i-1],\n",
        "                    hidden_channels[i],\n",
        "                    aggr=aggregation_methods[i]\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if self.residual:\n",
        "            self.projections = nn.ModuleList()\n",
        "            for i in range(len(hidden_channels)-1):\n",
        "                self.projections.append(nn.Sequential(\n",
        "                    nn.Linear(hidden_channels[i], hidden_channels[i+1]),\n",
        "                    nn.BatchNorm1d(hidden_channels[i+1])\n",
        "                ))\n",
        "\n",
        "        self.linear = nn.Linear(hidden_channels[-1], out_channels)\n",
        "        self.dropouts = nn.ModuleList([\n",
        "            nn.Dropout(dropout) for _ in range(self.num_layers)\n",
        "        ])\n",
        "\n",
        "        self.batch_norms = nn.ModuleList([\n",
        "            nn.BatchNorm1d(hidden_dim) for hidden_dim in hidden_channels\n",
        "        ])\n",
        "\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                nn.init.zeros_(module.bias)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        if edge_weight is None:\n",
        "            edge_weight = torch.ones(edge_index.size(1), device=edge_index.device)\n",
        "\n",
        "        if self.training and self.edge_dropout_rate > 0:\n",
        "            edge_mask = torch.rand(edge_index.size(1), device=edge_index.device) >= self.edge_dropout_rate\n",
        "            edge_index = edge_index[:, edge_mask]\n",
        "            edge_weight = edge_weight[edge_mask]\n",
        "\n",
        "        residuals = []\n",
        "        x = self.layers[0](x, edge_index, edge_weight)\n",
        "        x = F.relu(x)\n",
        "        x = self.batch_norms[0](x)\n",
        "        x = self.dropouts[0](x)\n",
        "        residuals.append(x)\n",
        "        for i in range(1, self.num_layers):\n",
        "            h = self.layers[i](x, edge_index, edge_weight)\n",
        "            h = F.relu(h)\n",
        "            h = self.batch_norms[i](h)\n",
        "\n",
        "            if self.residual and i > 0:\n",
        "                projected = self.projections[i-1](residuals[i-1])\n",
        "                h = h + projected\n",
        "\n",
        "            h = self.dropouts[i](h)\n",
        "            residuals.append(h)\n",
        "            x = h\n",
        "\n",
        "        return self.linear(x)\n",
        "\n",
        "class EdgeDropout(nn.Module):\n",
        "    def __init__(self, p=0.1):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        if not self.training or self.p == 0:\n",
        "            return edge_index\n",
        "        edge_mask = torch.rand(edge_index.size(1), device=edge_index.device) >= self.p\n",
        "        return edge_index[:, edge_mask]\n",
        "\n"
      ],
      "metadata": {
        "id": "vzDtRenSsu9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graph_smote(x, edge_index, y, minority_class=1, k_neighbors=5, n_synthetic=None):\n",
        "\n",
        "    minority_mask = (y == minority_class)\n",
        "    majority_mask = (y == 0) & (y != -1)\n",
        "\n",
        "    minority_indices = torch.nonzero(minority_mask).squeeze()\n",
        "    majority_indices = torch.nonzero(majority_mask).squeeze()\n",
        "\n",
        "    if minority_indices.dim() == 0:\n",
        "        minority_indices = minority_indices.unsqueeze(0)\n",
        "\n",
        "    if majority_indices.dim() == 0:\n",
        "        majority_indices = majority_indices.unsqueeze(0)\n",
        "\n",
        "    if minority_indices.numel() == 0:\n",
        "        return x, edge_index, y\n",
        "\n",
        "    if n_synthetic is None:\n",
        "        n_synthetic = len(majority_indices) - len(minority_indices)\n",
        "\n",
        "    if n_synthetic <= 0:\n",
        "        return x, edge_index, y\n",
        "\n",
        "    row, col = edge_index\n",
        "    N = x.size(0)\n",
        "\n",
        "    synthetic_features = []\n",
        "    new_edges = []\n",
        "\n",
        "    for _ in range(n_synthetic):\n",
        "        idx = minority_indices[torch.randint(0, len(minority_indices), (1,))]\n",
        "\n",
        "        neighbors = []\n",
        "        last_nodes = {idx.item()}\n",
        "        visited = set(last_nodes)\n",
        "\n",
        "        for _ in range(2):\n",
        "            current = set()\n",
        "            for node in last_nodes:\n",
        "                neighbor_indices = col[row == node].tolist()\n",
        "                same_class_neighbors = [n for n in neighbor_indices\n",
        "                                       if n not in visited and\n",
        "                                       n < len(y) and y[n].item() == minority_class]\n",
        "                current.update(same_class_neighbors)\n",
        "                neighbors.extend(same_class_neighbors)\n",
        "            visited.update(current)\n",
        "            last_nodes = current\n",
        "            if len(neighbors) >= k_neighbors:\n",
        "                break\n",
        "\n",
        "        if len(neighbors) < 2:\n",
        "            dists = torch.norm(x[idx].unsqueeze(0) - x[minority_indices], dim=1)\n",
        "            _, nn_indices = torch.topk(dists, min(k_neighbors + 1, len(minority_indices)), largest=False)\n",
        "            neighbors = [minority_indices[i].item() for i in nn_indices[1:]]\n",
        "\n",
        "        if not neighbors:\n",
        "            continue\n",
        "\n",
        "        neighbor_idx = neighbors[torch.randint(0, len(neighbors), (1,)).item()]\n",
        "        alpha = torch.rand(1).item()\n",
        "        synthetic_feature = alpha * x[idx] + (1 - alpha) * x[neighbor_idx]\n",
        "        synthetic_features.append(synthetic_feature)\n",
        "\n",
        "        src_neighbors = col[row == idx.item()].tolist()\n",
        "        dst_neighbors = col[row == neighbor_idx].tolist()\n",
        "        parent_neighbors = set(src_neighbors + dst_neighbors)\n",
        "\n",
        "        for neighbor in parent_neighbors:\n",
        "            new_edges.append((N + len(synthetic_features) - 1, neighbor))\n",
        "            new_edges.append((neighbor, N + len(synthetic_features) - 1))\n",
        "\n",
        "    if synthetic_features:\n",
        "        try:\n",
        "            print(f\"Debug - x shape: {x.shape}, num synthetic features: {len(synthetic_features)}\")\n",
        "            print(f\"First synthetic feature shape: {synthetic_features[0].shape}\")\n",
        "            synthetic_features_tensor = torch.stack(synthetic_features)\n",
        "            if len(x.shape) == 2 and len(synthetic_features_tensor.shape) == 2:\n",
        "                new_x = torch.cat([x, synthetic_features_tensor], dim=0)\n",
        "            elif len(x.shape) == 2 and len(synthetic_features_tensor.shape) == 3:\n",
        "                synthetic_reshaped = synthetic_features_tensor.view(-1, x.shape[1])\n",
        "                new_x = torch.cat([x, synthetic_reshaped], dim=0)\n",
        "            else:\n",
        "                print(f\"Warning: Dimension mismatch. x: {x.shape}, synthetic: {synthetic_features_tensor.shape}\")\n",
        "                if x.shape[1:] != synthetic_features_tensor.shape[1:]:\n",
        "                    reshaped_features = []\n",
        "                    for feat in synthetic_features:\n",
        "                        reshaped = feat.view(1, -1)\n",
        "                        if reshaped.shape[1] != x.shape[1]:\n",
        "                            if reshaped.shape[1] < x.shape[1]:\n",
        "                                padding = torch.zeros(1, x.shape[1] - reshaped.shape[1],\n",
        "                                                     device=reshaped.device)\n",
        "                                reshaped = torch.cat([reshaped, padding], dim=1)\n",
        "                            else:\n",
        "                                reshaped = reshaped[:, :x.shape[1]]\n",
        "                        reshaped_features.append(reshaped)\n",
        "                    if reshaped_features:\n",
        "                        synthetic_features_tensor = torch.cat(reshaped_features, dim=0)\n",
        "                        new_x = torch.cat([x, synthetic_features_tensor], dim=0)\n",
        "                    else:\n",
        "                        print(\"Warning: Failed to reshape synthetic features, returning original data\")\n",
        "                        return x, edge_index, y\n",
        "\n",
        "            print(f\"Success - new_x shape: {new_x.shape}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error in graph_smote feature concatenation: {str(e)}\")\n",
        "            print(f\"x shape: {x.shape}, synthetic features: {len(synthetic_features)}\")\n",
        "            return x, edge_index, y\n",
        "\n",
        "        new_labels = torch.full((len(synthetic_features),), minority_class,\n",
        "                               dtype=y.dtype, device=y.device)\n",
        "        new_y = torch.cat([y, new_labels])\n",
        "        if new_edges:\n",
        "            new_edge_indices = torch.tensor(new_edges, dtype=edge_index.dtype,\n",
        "                                           device=edge_index.device).t()\n",
        "            new_edge_index = torch.cat([edge_index, new_edge_indices], dim=1)\n",
        "        else:\n",
        "            new_edge_index = edge_index\n",
        "\n",
        "        return new_x, new_edge_index, new_y\n",
        "\n",
        "    return x, edge_index, y\n",
        "\n",
        "def weight_minority_edges(edge_index, y, edge_weights=None, minority_class=1, weight_factor=2.0):\n",
        "\n",
        "    source, target = edge_index\n",
        "    if edge_weights is None:\n",
        "        edge_weights = torch.ones(edge_index.size(1), device=edge_index.device)\n",
        "\n",
        "    for i in range(edge_index.size(1)):\n",
        "        src_node, tgt_node = source[i].item(), target[i].item()\n",
        "        if src_node < len(y) and tgt_node < len(y):\n",
        "\n",
        "            if y[src_node] == minority_class and y[tgt_node] == minority_class:\n",
        "                edge_weights[i] = weight_factor * weight_factor\n",
        "\n",
        "            elif y[src_node] == minority_class or y[tgt_node] == minority_class:\n",
        "                edge_weights[i] = weight_factor\n",
        "\n",
        "    return edge_weights\n",
        "\n",
        "def analyze_oversampling_impact(self, model, test_timesteps, num_neighbors):\n",
        "    print(\"\\n=== Analyzing Oversampling Impact ===\")\n",
        "\n",
        "    results_with_oversampling = []\n",
        "    results_without_oversampling = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for test_timestep in test_timesteps:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "            standard_data = self.data_handler.process_timestep_with_sampling(\n",
        "                self.df_edges,\n",
        "                self.df_features,\n",
        "                test_timestep,\n",
        "                num_neighbors\n",
        "            ).to(self.device)\n",
        "\n",
        "            oversampled_data = self.data_handler.process_timestep_with_sampling(\n",
        "                self.df_edges,\n",
        "                self.df_features,\n",
        "                test_timestep,\n",
        "                num_neighbors\n",
        "            ).to(self.device)\n",
        "\n",
        "            valid_mask_std = (standard_data.y != -1)\n",
        "            if valid_mask_std.sum() > 0:\n",
        "                out_std = model(standard_data.x, standard_data.edge_index)\n",
        "                probs_std = F.softmax(out_std[valid_mask_std], dim=1)\n",
        "                preds_std = (probs_std[:, 1] >= self.optimal_threshold).long()\n",
        "\n",
        "                y_true_std = standard_data.y[valid_mask_std].cpu().numpy()\n",
        "                y_pred_std = preds_std.cpu().numpy()\n",
        "                y_prob_std = probs_std.cpu().numpy()\n",
        "\n",
        "                if len(np.unique(y_true_std)) > 1:\n",
        "                    metrics_std = self.calculate_metrics(y_true_std, y_pred_std, y_prob_std)\n",
        "                    metrics_std['timestep'] = test_timestep\n",
        "                    results_without_oversampling.append(metrics_std)\n",
        "\n",
        "            valid_mask_over = (oversampled_data.y != -1)\n",
        "            if hasattr(oversampled_data, 'original_indices'):\n",
        "                valid_mask_over = valid_mask_over & (oversampled_data.original_indices != -1)\n",
        "\n",
        "            if valid_mask_over.sum() > 0:\n",
        "                if hasattr(oversampled_data, 'edge_weight'):\n",
        "                    out_over = model(oversampled_data.x, oversampled_data.edge_index,\n",
        "                                     oversampled_data.edge_weight)\n",
        "                else:\n",
        "                    out_over = model(oversampled_data.x, oversampled_data.edge_index)\n",
        "\n",
        "                probs_over = F.softmax(out_over[valid_mask_over], dim=1)\n",
        "                preds_over = (probs_over[:, 1] >= self.optimal_threshold).long()\n",
        "\n",
        "                y_true_over = oversampled_data.y[valid_mask_over].cpu().numpy()\n",
        "                y_pred_over = preds_over.cpu().numpy()\n",
        "                y_prob_over = probs_over.cpu().numpy()\n",
        "\n",
        "                if len(np.unique(y_true_over)) > 1:\n",
        "                    metrics_over = self.calculate_metrics(y_true_over, y_pred_over, y_prob_over)\n",
        "                    metrics_over['timestep'] = test_timestep\n",
        "                    results_with_oversampling.append(metrics_over)\n",
        "\n",
        "    if results_without_oversampling and results_with_oversampling:\n",
        "        print(\"\\nAverage Metrics Without Oversampling:\")\n",
        "        avg_without = {\n",
        "            key: np.mean([r[key] for r in results_without_oversampling if key in r])\n",
        "            for key in results_without_oversampling[0].keys()\n",
        "            if key != 'timestep' and key != 'confusion_matrix'\n",
        "        }\n",
        "\n",
        "        for metric, value in avg_without.items():\n",
        "            print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "        print(\"\\nAverage Metrics With Oversampling:\")\n",
        "        avg_with = {\n",
        "            key: np.mean([r[key] for r in results_with_oversampling if key in r])\n",
        "            for key in results_with_oversampling[0].keys()\n",
        "            if key != 'timestep' and key != 'confusion_matrix'\n",
        "        }\n",
        "\n",
        "        for metric, value in avg_with.items():\n",
        "            print(f\"  {metric}: {value:.4f}\")\n",
        "\n",
        "        print(\"\\nDifference (With - Without):\")\n",
        "        for metric in avg_with.keys():\n",
        "            diff = avg_with[metric] - avg_without[metric]\n",
        "            print(f\"  {metric}: {diff:.4f} ({'improved' if diff > 0 else 'decreased'})\")\n",
        "\n",
        "        if self.wandb_run is not None:\n",
        "            self.wandb_run.log({\n",
        "                **{f'std_{k}': v for k, v in avg_without.items()},\n",
        "                **{f'over_{k}': v for k, v in avg_with.items()},\n",
        "                **{f'diff_{k}': avg_with[k] - avg_without[k] for k in avg_with.keys()}\n",
        "            })\n",
        "\n",
        "    return {\n",
        "        'without_oversampling': avg_without if results_without_oversampling else {},\n",
        "        'with_oversampling': avg_with if results_with_oversampling else {}\n",
        "    }\n",
        "\n",
        "class CustomSAGEConv(MessagePassing):\n",
        "    def __init__(self, in_channels, out_channels, aggr='mean'):\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        self.lin_self = nn.Linear(in_channels, out_channels)\n",
        "        self.lin_neigh = nn.Linear(in_channels, out_channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_self.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_neigh.weight)\n",
        "\n",
        "    def forward(self, x, edge_index, edge_weight=None):\n",
        "        out = self.propagate(edge_index, x=x, edge_weight=edge_weight)\n",
        "        out = self.lin_neigh(out)\n",
        "        out = out + self.lin_self(x)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j, edge_weight=None):\n",
        "        if edge_weight is not None:\n",
        "            return x_j * edge_weight.view(-1, 1)\n",
        "        return x_j\n",
        "\n",
        "\n",
        "def preprocess_with_smote(df_features, df_edges, oversample_ratio=30.0):\n",
        "    print(\"\\n=== Preprocessing with GraphSMOTE ===\")\n",
        "    features_df = df_features.copy()\n",
        "    edges_df = df_edges.copy()\n",
        "\n",
        "    max_node_id = features_df['node_id'].max()\n",
        "    if isinstance(max_node_id, str):\n",
        "        max_node_id = max([int(nid.split('_')[-1]) if '_' in nid else 0\n",
        "                          for nid in features_df['node_id']])\n",
        "    next_node_id = max_node_id + 1\n",
        "    new_nodes = []\n",
        "    new_edges = []\n",
        "    all_timesteps = sorted(features_df['Time step'].unique())\n",
        "\n",
        "    for timestep in all_timesteps:\n",
        "        timestep_features = features_df[features_df['Time step'] == timestep]\n",
        "\n",
        "        if 'binary_class' in timestep_features.columns:\n",
        "            minority_nodes = timestep_features[timestep_features['binary_class'] == 1]\n",
        "            majority_nodes = timestep_features[timestep_features['binary_class'] == 0]\n",
        "        else:\n",
        "            minority_nodes = timestep_features[timestep_features['class'] == 1]\n",
        "            majority_nodes = timestep_features[timestep_features['class'] == 2]\n",
        "\n",
        "        if len(minority_nodes) == 0 or len(minority_nodes) >= len(majority_nodes):\n",
        "            print(f\"Timestep {timestep}: Skipping (minority: {len(minority_nodes)}, majority: {len(majority_nodes)})\")\n",
        "            continue\n",
        "\n",
        "        target_samples = min(int(len(minority_nodes) * oversample_ratio), len(majority_nodes))\n",
        "        samples_to_generate = max(0, target_samples - len(minority_nodes))\n",
        "\n",
        "        print(f\"Timestep {timestep}: Oversampling minority class. Original: {len(minority_nodes)}, Target: {target_samples}\")\n",
        "\n",
        "        if samples_to_generate == 0:\n",
        "            continue\n",
        "\n",
        "        node_to_idx = {node: idx for idx, node in enumerate(timestep_features['node_id'])}\n",
        "        idx_to_node = {idx: node for node, idx in node_to_idx.items()}\n",
        "\n",
        "        feature_cols = timestep_features.columns.difference(['node_id', 'Time step', 'class', 'binary_class'])\n",
        "        X = torch.tensor(timestep_features[feature_cols].values, dtype=torch.float32)\n",
        "\n",
        "        if 'binary_class' in timestep_features.columns:\n",
        "            y = torch.tensor(timestep_features['binary_class'].values, dtype=torch.long)\n",
        "        else:\n",
        "            y = torch.tensor(timestep_features['class'].map(lambda x: 1 if x == 1 else (0 if x == 2 else -1)).values,\n",
        "                             dtype=torch.long)\n",
        "\n",
        "        timestep_edges = edges_df[\n",
        "            edges_df['source'].isin(timestep_features['node_id']) &\n",
        "            edges_df['target'].isin(timestep_features['node_id'])\n",
        "        ]\n",
        "\n",
        "        edge_index = []\n",
        "        for _, edge in timestep_edges.iterrows():\n",
        "            if edge['source'] in node_to_idx and edge['target'] in node_to_idx:\n",
        "                edge_index.append([node_to_idx[edge['source']], node_to_idx[edge['target']]])\n",
        "\n",
        "        edge_index = torch.tensor(edge_index, dtype=torch.long).t() if edge_index else torch.zeros((2, 0), dtype=torch.long)\n",
        "\n",
        "        try:\n",
        "            new_X, new_edge_index, new_y = graph_smote(\n",
        "                X, edge_index, y,\n",
        "                minority_class=1,\n",
        "                k_neighbors=5,\n",
        "                n_synthetic=samples_to_generate\n",
        "            )\n",
        "\n",
        "            num_original_nodes = X.size(0)\n",
        "            num_synthetic_nodes = new_X.size(0) - num_original_nodes\n",
        "\n",
        "            if num_synthetic_nodes > 0:\n",
        "                print(f\"  Created {num_synthetic_nodes} synthetic nodes.\")\n",
        "\n",
        "                for i in range(num_original_nodes, new_X.size(0)):\n",
        "\n",
        "                    if isinstance(max_node_id, str):\n",
        "                        new_id = f\"synthetic_{next_node_id}\"\n",
        "                    else:\n",
        "                        new_id = f\"synthetic_{next_node_id}\"\n",
        "                    next_node_id += 1\n",
        "\n",
        "                    node_data = {\n",
        "                        'node_id': new_id,\n",
        "                        'Time step': timestep,\n",
        "                        'binary_class': new_y[i].item(),\n",
        "                        'class': 1 if new_y[i].item() == 1 else 2,\n",
        "                        **{col: new_X[i, j].item() for j, col in enumerate(feature_cols)}\n",
        "                    }\n",
        "                    new_nodes.append(node_data)\n",
        "\n",
        "                    idx_to_node[i] = new_id\n",
        "\n",
        "                for j in range(new_edge_index.size(1)):\n",
        "                    src_idx, dst_idx = new_edge_index[0, j].item(), new_edge_index[1, j].item()\n",
        "                    if src_idx >= num_original_nodes or dst_idx >= num_original_nodes:\n",
        "                        if src_idx in idx_to_node and dst_idx in idx_to_node:\n",
        "                            new_edges.append({\n",
        "                                'source': idx_to_node[src_idx],\n",
        "                                'target': idx_to_node[dst_idx]\n",
        "                            })\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in GraphSMOTE for timestep {timestep}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if new_nodes:\n",
        "        synthetic_nodes_df = pd.DataFrame(new_nodes)\n",
        "        oversampled_features = pd.concat([features_df, synthetic_nodes_df], ignore_index=True)\n",
        "        print(f\"Added {len(synthetic_nodes_df)} synthetic nodes to features DataFrame.\")\n",
        "    else:\n",
        "        oversampled_features = features_df\n",
        "        print(\"No synthetic nodes were added.\")\n",
        "\n",
        "    if new_edges:\n",
        "        synthetic_edges_df = pd.DataFrame(new_edges)\n",
        "        oversampled_edges = pd.concat([edges_df, synthetic_edges_df], ignore_index=True)\n",
        "        print(f\"Added {len(synthetic_edges_df)} synthetic edges to edges DataFrame.\")\n",
        "    else:\n",
        "        oversampled_edges = edges_df\n",
        "        print(\"No synthetic edges were added.\")\n",
        "\n",
        "    if 'binary_class' in oversampled_features.columns:\n",
        "        print(\"\\nClass distribution after oversampling:\")\n",
        "        print(oversampled_features['binary_class'].value_counts().sort_index())\n",
        "    else:\n",
        "        print(\"\\nClass distribution after oversampling:\")\n",
        "        print(oversampled_features['class'].value_counts().sort_index())\n",
        "\n",
        "    return oversampled_features, oversampled_edges\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5bVYpMk9yBxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "trainer = EnhancedModelTrainer(\n",
        "    checkpoint_dir=Path(save_path) / 'processed_data',\n",
        "    wandb_project='Sage_',\n",
        "    wandb_entity='ziprikk-university-duisburg',\n",
        "    wandb_run=wandb.init(\n",
        "        project='Sage_',\n",
        "        entity='ziprikk-university-duisburg',\n",
        "        config={\n",
        "            \"optimizer\": \"Adam\",\n",
        "            \"architecture\": \"AdvancedGraphSAGE\",\n",
        "            \"balance_strategy\": \"class_weights+focal_loss\",\n",
        "            \"evaluation\": \"cross_validation\"\n",
        "        }\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bZ7X5fbxBxTO",
        "outputId": "99d13ad8-631f-4b2c-901e-0d9289975464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250402_075903-nnjfkq08</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ziprikk-university-duisburg/Sage_/runs/nnjfkq08' target=\"_blank\">treasured-energy-35</a></strong> to <a href='https://wandb.ai/ziprikk-university-duisburg/Sage_' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ziprikk-university-duisburg/Sage_' target=\"_blank\">https://wandb.ai/ziprikk-university-duisburg/Sage_</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ziprikk-university-duisburg/Sage_/runs/nnjfkq08' target=\"_blank\">https://wandb.ai/ziprikk-university-duisburg/Sage_/runs/nnjfkq08</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using device: cuda:0\n",
            "Initial GPU memory allocated: 0.00 MB\n",
            "Initial GPU memory cached: 0.00 MB\n",
            "\n",
            "=== Preprocessing with GraphSMOTE (Timesteps 1-36) ===\n",
            "Will only process timesteps: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
            "Timestep 1: Oversampling minority class. Original: 96, Target: 4800\n",
            "Debug - x shape: torch.Size([51108, 55]), num synthetic features: 1801\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([52909, 55])\n",
            "  Created 1801 synthetic nodes.\n",
            "Timestep 2: Oversampling minority class. Original: 99, Target: 4950\n",
            "Debug - x shape: torch.Size([32269, 55]), num synthetic features: 1435\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([33704, 55])\n",
            "  Created 1435 synthetic nodes.\n",
            "Timestep 3: Oversampling minority class. Original: 58, Target: 2900\n",
            "Debug - x shape: torch.Size([31106, 55]), num synthetic features: 862\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([31968, 55])\n",
            "  Created 862 synthetic nodes.\n",
            "Timestep 4: Oversampling minority class. Original: 266, Target: 8647\n",
            "Debug - x shape: torch.Size([39948, 55]), num synthetic features: 1727\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([41675, 55])\n",
            "  Created 1727 synthetic nodes.\n",
            "Timestep 5: Oversampling minority class. Original: 54, Target: 2700\n",
            "Debug - x shape: torch.Size([35140, 55]), num synthetic features: 979\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([36119, 55])\n",
            "  Created 979 synthetic nodes.\n",
            "Timestep 6: Oversampling minority class. Original: 17, Target: 850\n",
            "Debug - x shape: torch.Size([19003, 55]), num synthetic features: 42\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([19045, 55])\n",
            "  Created 42 synthetic nodes.\n",
            "Timestep 7: Oversampling minority class. Original: 463, Target: 7902\n",
            "Debug - x shape: torch.Size([31722, 55]), num synthetic features: 984\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([32706, 55])\n",
            "  Created 984 synthetic nodes.\n",
            "Timestep 8: Oversampling minority class. Original: 267, Target: 13350\n",
            "Debug - x shape: torch.Size([34127, 55]), num synthetic features: 1794\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([35921, 55])\n",
            "  Created 1794 synthetic nodes.\n",
            "Timestep 9: Oversampling minority class. Original: 960, Target: 3894\n",
            "Debug - x shape: torch.Size([28673, 55]), num synthetic features: 327\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([29000, 55])\n",
            "  Created 327 synthetic nodes.\n",
            "Timestep 10: Oversampling minority class. Original: 120, Target: 6000\n",
            "Debug - x shape: torch.Size([46845, 55]), num synthetic features: 338\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([47183, 55])\n",
            "  Created 338 synthetic nodes.\n",
            "Timestep 11: Oversampling minority class. Original: 494, Target: 10576\n",
            "Debug - x shape: torch.Size([29320, 55]), num synthetic features: 695\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([30015, 55])\n",
            "  Created 695 synthetic nodes.\n",
            "Timestep 12: Oversampling minority class. Original: 77, Target: 2875\n",
            "Debug - x shape: torch.Size([13295, 55]), num synthetic features: 799\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([14094, 55])\n",
            "  Created 799 synthetic nodes.\n",
            "Timestep 13: Oversampling minority class. Original: 918, Target: 3288\n",
            "Debug - x shape: torch.Size([31019, 55]), num synthetic features: 143\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([31162, 55])\n",
            "  Created 143 synthetic nodes.\n",
            "Timestep 14: Oversampling minority class. Original: 156, Target: 1941\n",
            "Debug - x shape: torch.Size([8009, 55]), num synthetic features: 259\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([8268, 55])\n",
            "  Created 259 synthetic nodes.\n",
            "Timestep 15: Oversampling minority class. Original: 447, Target: 6671\n",
            "Debug - x shape: torch.Size([18618, 55]), num synthetic features: 432\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([19050, 55])\n",
            "  Created 432 synthetic nodes.\n",
            "Timestep 16: Oversampling minority class. Original: 427, Target: 2315\n",
            "Debug - x shape: torch.Size([11806, 55]), num synthetic features: 148\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([11954, 55])\n",
            "  Created 148 synthetic nodes.\n",
            "Timestep 17: Oversampling minority class. Original: 321, Target: 4039\n",
            "Debug - x shape: torch.Size([21426, 55]), num synthetic features: 165\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([21591, 55])\n",
            "  Created 165 synthetic nodes.\n",
            "Timestep 18: Oversampling minority class. Original: 189, Target: 1643\n",
            "Debug - x shape: torch.Size([8245, 55]), num synthetic features: 118\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([8363, 55])\n",
            "  Created 118 synthetic nodes.\n",
            "Timestep 19: Oversampling minority class. Original: 320, Target: 3220\n",
            "Debug - x shape: torch.Size([15173, 55]), num synthetic features: 391\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([15564, 55])\n",
            "  Created 391 synthetic nodes.\n",
            "Timestep 20: Oversampling minority class. Original: 950, Target: 6315\n",
            "Debug - x shape: torch.Size([39748, 55]), num synthetic features: 839\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([40587, 55])\n",
            "  Created 839 synthetic nodes.\n",
            "Timestep 21: Oversampling minority class. Original: 1256, Target: 16576\n",
            "Debug - x shape: torch.Size([39557, 55]), num synthetic features: 658\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([40215, 55])\n",
            "  Created 658 synthetic nodes.\n",
            "Timestep 22: Oversampling minority class. Original: 1491, Target: 9693\n",
            "Debug - x shape: torch.Size([40011, 55]), num synthetic features: 440\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([40451, 55])\n",
            "  Created 440 synthetic nodes.\n",
            "Timestep 23: Oversampling minority class. Original: 734, Target: 7301\n",
            "Debug - x shape: torch.Size([22136, 55]), num synthetic features: 603\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([22739, 55])\n",
            "  Created 603 synthetic nodes.\n",
            "Timestep 24: Oversampling minority class. Original: 1083, Target: 3518\n",
            "Debug - x shape: torch.Size([23997, 55]), num synthetic features: 208\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([24205, 55])\n",
            "  Created 208 synthetic nodes.\n",
            "Timestep 25: Oversampling minority class. Original: 2243, Target: 8314\n",
            "Debug - x shape: torch.Size([22788, 55]), num synthetic features: 98\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([22886, 55])\n",
            "  Created 98 synthetic nodes.\n",
            "Timestep 26: Oversampling minority class. Original: 1334, Target: 2360\n",
            "Debug - x shape: torch.Size([20128, 55]), num synthetic features: 81\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([20209, 55])\n",
            "  Created 81 synthetic nodes.\n",
            "Timestep 27: Oversampling minority class. Original: 89, Target: 1000\n",
            "Debug - x shape: torch.Size([10219, 55]), num synthetic features: 101\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([10320, 55])\n",
            "  Created 101 synthetic nodes.\n",
            "Timestep 28: Oversampling minority class. Original: 219, Target: 920\n",
            "Debug - x shape: torch.Size([7628, 55]), num synthetic features: 21\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([7649, 55])\n",
            "  Created 21 synthetic nodes.\n",
            "Timestep 29: Oversampling minority class. Original: 979, Target: 3811\n",
            "Debug - x shape: torch.Size([21970, 55]), num synthetic features: 301\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([22271, 55])\n",
            "  Created 301 synthetic nodes.\n",
            "Timestep 30: Oversampling minority class. Original: 287, Target: 2931\n",
            "Debug - x shape: torch.Size([12100, 55]), num synthetic features: 377\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([12477, 55])\n",
            "  Created 377 synthetic nodes.\n",
            "Timestep 31: Oversampling minority class. Original: 312, Target: 5119\n",
            "Debug - x shape: torch.Size([18759, 55]), num synthetic features: 457\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([19216, 55])\n",
            "  Created 457 synthetic nodes.\n",
            "Timestep 32: Oversampling minority class. Original: 1730, Target: 4873\n",
            "Debug - x shape: torch.Size([22282, 55]), num synthetic features: 114\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([22396, 55])\n",
            "  Created 114 synthetic nodes.\n",
            "Timestep 33: Oversampling minority class. Original: 561, Target: 7675\n",
            "Debug - x shape: torch.Size([18345, 55]), num synthetic features: 208\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([18553, 55])\n",
            "  Created 208 synthetic nodes.\n",
            "Timestep 34: Oversampling minority class. Original: 908, Target: 5546\n",
            "Debug - x shape: torch.Size([16368, 55]), num synthetic features: 156\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([16524, 55])\n",
            "  Created 156 synthetic nodes.\n",
            "Timestep 35: Oversampling minority class. Original: 943, Target: 6229\n",
            "Debug - x shape: torch.Size([31070, 55]), num synthetic features: 221\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([31291, 55])\n",
            "  Created 221 synthetic nodes.\n",
            "Timestep 36: Oversampling minority class. Original: 1226, Target: 11130\n",
            "Debug - x shape: torch.Size([47243, 55]), num synthetic features: 9\n",
            "First synthetic feature shape: torch.Size([1, 55])\n",
            "Success - new_x shape: torch.Size([47252, 55])\n",
            "  Created 9 synthetic nodes.\n",
            "Added 18331 synthetic nodes to features DataFrame.\n",
            "Added 112026 synthetic edges to edges DataFrame.\n",
            "\n",
            "Class distribution after oversampling:\n",
            "binary_class\n",
            "1.0    18331\n",
            "Name: count, dtype: int64\n",
            "\n",
            "=== Summary of GraphSMOTE Preprocessing ===\n",
            "Only processed timesteps 1 to 36\n",
            "Total synthetic nodes added: 18331\n",
            "Total synthetic edges added: 112026\n",
            "\n",
            "Feature details:\n",
            "Number of features: 55\n",
            "\n",
            "Feature names:\n",
            "1. blocks_btwn_input_txs_max\n",
            "2. blocks_btwn_input_txs_mean\n",
            "3. blocks_btwn_input_txs_median\n",
            "4. blocks_btwn_input_txs_min\n",
            "5. blocks_btwn_input_txs_total\n",
            "6. blocks_btwn_output_txs_max\n",
            "7. blocks_btwn_output_txs_mean\n",
            "8. blocks_btwn_output_txs_median\n",
            "9. blocks_btwn_output_txs_min\n",
            "10. blocks_btwn_output_txs_total\n",
            "11. blocks_btwn_txs_max\n",
            "12. blocks_btwn_txs_mean\n",
            "13. blocks_btwn_txs_median\n",
            "14. blocks_btwn_txs_min\n",
            "15. blocks_btwn_txs_total\n",
            "16. btc_received_max\n",
            "17. btc_received_mean\n",
            "18. btc_received_median\n",
            "19. btc_received_min\n",
            "20. btc_received_total\n",
            "21. btc_sent_max\n",
            "22. btc_sent_mean\n",
            "23. btc_sent_median\n",
            "24. btc_sent_min\n",
            "25. btc_sent_total\n",
            "26. btc_transacted_max\n",
            "27. btc_transacted_mean\n",
            "28. btc_transacted_median\n",
            "29. btc_transacted_min\n",
            "30. btc_transacted_total\n",
            "31. fees_as_share_max\n",
            "32. fees_as_share_mean\n",
            "33. fees_as_share_median\n",
            "34. fees_as_share_min\n",
            "35. fees_as_share_total\n",
            "36. fees_max\n",
            "37. fees_mean\n",
            "38. fees_median\n",
            "39. fees_min\n",
            "40. fees_total\n",
            "41. first_block_appeared_in\n",
            "42. first_received_block\n",
            "43. first_sent_block\n",
            "44. last_block_appeared_in\n",
            "45. lifetime_in_blocks\n",
            "46. num_addr_transacted_multiple\n",
            "47. num_timesteps_appeared_in\n",
            "48. num_txs_as_receiver\n",
            "49. num_txs_as_sender\n",
            "50. total_txs\n",
            "51. transacted_w_address_max\n",
            "52. transacted_w_address_mean\n",
            "53. transacted_w_address_median\n",
            "54. transacted_w_address_min\n",
            "55. transacted_w_address_total\n",
            "\n",
            "Feature statistics:\n",
            "       blocks_btwn_input_txs_max  blocks_btwn_input_txs_mean  \\\n",
            "count               1.286591e+06                1.286591e+06   \n",
            "mean                1.217027e+03                5.975059e+02   \n",
            "std                 5.754681e+03                3.797373e+03   \n",
            "min                 0.000000e+00                0.000000e+00   \n",
            "25%                 0.000000e+00                0.000000e+00   \n",
            "50%                 0.000000e+00                0.000000e+00   \n",
            "75%                 0.000000e+00                0.000000e+00   \n",
            "max                 9.475800e+04                9.475800e+04   \n",
            "\n",
            "       blocks_btwn_input_txs_median  blocks_btwn_input_txs_min  \\\n",
            "count                  1.286591e+06               1.286591e+06   \n",
            "mean                   5.421751e+02               4.151474e+02   \n",
            "std                    3.734480e+03               3.390249e+03   \n",
            "min                    0.000000e+00               0.000000e+00   \n",
            "25%                    0.000000e+00               0.000000e+00   \n",
            "50%                    0.000000e+00               0.000000e+00   \n",
            "75%                    0.000000e+00               0.000000e+00   \n",
            "max                    9.475800e+04               9.475800e+04   \n",
            "\n",
            "       blocks_btwn_input_txs_total  blocks_btwn_output_txs_max  \\\n",
            "count                 1.286591e+06                1.286591e+06   \n",
            "mean                  2.611608e+03                2.846515e+03   \n",
            "std                   1.258589e+04                8.345023e+03   \n",
            "min                   0.000000e+00                0.000000e+00   \n",
            "25%                   0.000000e+00                0.000000e+00   \n",
            "50%                   0.000000e+00                0.000000e+00   \n",
            "75%                   0.000000e+00                0.000000e+00   \n",
            "max                   9.677300e+04                9.676700e+04   \n",
            "\n",
            "       blocks_btwn_output_txs_mean  blocks_btwn_output_txs_median  \\\n",
            "count                 1.286591e+06                   1.286591e+06   \n",
            "mean                  1.736253e+03                   1.630296e+03   \n",
            "std                   5.846045e+03                   5.814110e+03   \n",
            "min                   0.000000e+00                   0.000000e+00   \n",
            "25%                   0.000000e+00                   0.000000e+00   \n",
            "50%                   0.000000e+00                   0.000000e+00   \n",
            "75%                   0.000000e+00                   0.000000e+00   \n",
            "max                   9.676700e+04                   9.676700e+04   \n",
            "\n",
            "       blocks_btwn_output_txs_min  blocks_btwn_output_txs_total  ...  \\\n",
            "count                1.286591e+06                  1.286591e+06  ...   \n",
            "mean                 1.138922e+03                  4.991248e+03  ...   \n",
            "std                  4.975284e+03                  1.577909e+04  ...   \n",
            "min                  0.000000e+00                  0.000000e+00  ...   \n",
            "25%                  0.000000e+00                  0.000000e+00  ...   \n",
            "50%                  0.000000e+00                  0.000000e+00  ...   \n",
            "75%                  0.000000e+00                  0.000000e+00  ...   \n",
            "max                  9.676700e+04                  9.676900e+04  ...   \n",
            "\n",
            "       num_addr_transacted_multiple  num_timesteps_appeared_in  \\\n",
            "count                  1.286591e+06               1.286591e+06   \n",
            "mean                   2.422500e+00               1.860591e+00   \n",
            "std                    3.834661e+01               3.871954e+00   \n",
            "min                    0.000000e+00               1.000000e+00   \n",
            "25%                    0.000000e+00               1.000000e+00   \n",
            "50%                    0.000000e+00               1.000000e+00   \n",
            "75%                    0.000000e+00               1.000000e+00   \n",
            "max                    7.167000e+03               4.700000e+01   \n",
            "\n",
            "       num_txs_as_receiver  num_txs_as_sender     total_txs  \\\n",
            "count         1.286591e+06       1.286591e+06  1.286591e+06   \n",
            "mean          6.495913e+00       1.253802e+01  1.903393e+01   \n",
            "std           4.550382e+01       8.805711e+01  1.156148e+02   \n",
            "min           0.000000e+00       0.000000e+00  1.000000e+00   \n",
            "25%           1.000000e+00       0.000000e+00  1.000000e+00   \n",
            "50%           1.000000e+00       1.000000e+00  2.000000e+00   \n",
            "75%           1.000000e+00       1.000000e+00  2.000000e+00   \n",
            "max           5.480000e+02       1.453000e+03  1.471000e+03   \n",
            "\n",
            "       transacted_w_address_max  transacted_w_address_mean  \\\n",
            "count              1.286591e+06               1.286591e+06   \n",
            "mean               2.286193e+00               1.075140e+00   \n",
            "std                1.012429e+01               4.854629e-01   \n",
            "min                1.000000e+00               1.000000e+00   \n",
            "25%                1.000000e+00               1.000000e+00   \n",
            "50%                1.000000e+00               1.000000e+00   \n",
            "75%                1.000000e+00               1.000000e+00   \n",
            "max                1.570000e+02               4.100000e+01   \n",
            "\n",
            "       transacted_w_address_median  transacted_w_address_min  \\\n",
            "count                 1.286591e+06              1.286591e+06   \n",
            "mean                  1.042219e+00              1.031314e+00   \n",
            "std                   4.323188e-01              3.923635e-01   \n",
            "min                   1.000000e+00              1.000000e+00   \n",
            "25%                   1.000000e+00              1.000000e+00   \n",
            "50%                   1.000000e+00              1.000000e+00   \n",
            "75%                   1.000000e+00              1.000000e+00   \n",
            "max                   4.100000e+01              4.100000e+01   \n",
            "\n",
            "       transacted_w_address_total  \n",
            "count                1.286591e+06  \n",
            "mean                 5.212176e+01  \n",
            "std                  4.484146e+02  \n",
            "min                  1.000000e+00  \n",
            "25%                  2.000000e+00  \n",
            "50%                  3.000000e+00  \n",
            "75%                  7.000000e+00  \n",
            "max                  3.784100e+04  \n",
            "\n",
            "[8 rows x 55 columns]\n",
            "\n",
            "Original class distribution:\n",
            "class\n",
            "1     46932\n",
            "2    338871\n",
            "3    900788\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique classes found in data: [1, 2, 3]\n",
            "Classes used for binary classification: [1, 2]\n",
            "\n",
            "Class mapping:\n",
            "Class 1 → 0\n",
            "Class 2 → 1\n",
            "Class 3 → -1 (excluded from training)\n",
            "\n",
            "Data split sizes (excluding class 3):\n",
            "Training nodes: 283526\n",
            "Validation nodes: 32382\n",
            "Test nodes: 69895\n",
            "\n",
            "=== Class Distribution Per Split ===\n",
            "\n",
            "Training set class distribution:\n",
            "binary_class\n",
            "0    243101\n",
            "1     40425\n",
            "Name: count, dtype: int64\n",
            "Class 0 percentage: 85.74%\n",
            "Class 1 percentage: 14.26%\n",
            "Class ratio (0:1): 1:0.17\n",
            "\n",
            "Validation set class distribution:\n",
            "binary_class\n",
            "0    29641\n",
            "1     2741\n",
            "Name: count, dtype: int64\n",
            "Class 0 percentage: 91.54%\n",
            "Class 1 percentage: 8.46%\n",
            "Class ratio (0:1): 1:0.09\n",
            "\n",
            "Test set class distribution:\n",
            "binary_class\n",
            "0    66129\n",
            "1     3766\n",
            "Name: count, dtype: int64\n",
            "Class 0 percentage: 94.61%\n",
            "Class 1 percentage: 5.39%\n",
            "Class ratio (0:1): 1:0.06\n",
            "\n",
            "Class weights calculated on RAW data (before oversampling):\n",
            "Class 0 weight: 1.0844\n",
            "Class 1 weight: 12.8482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#trainer.debug_mask_creation()\n",
        "# Run parameter search\n",
        "#print(\"Starting hyperparameter optimization...\")\n",
        "#best_params = trainer.run_parameter_search(n_trials=50)\n",
        "#print(f\"Best parameters found: {best_params}\")\n"
      ],
      "metadata": {
        "id": "jdKdYFUEHzXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = {\n",
        "    'num_layers': 1,\n",
        "    'base_channels': 240,\n",
        "    'dropout': 0.43531998658753374,\n",
        "    'learning_rate': 4.890518499140206e-05,\n",
        "    'weight_decay': 0.0015759308553133077,\n",
        "    'residual': False,\n",
        "    'activation': 'leaky_relu',\n",
        "    'edge_dropout': 0.01765443283938786,\n",
        "    'focal_gamma': 2.7905145019036874,\n",
        "    'class_weight_factor': 1.0296382120174215,\n",
        "    'max_neighbors': 7,\n",
        "    'layer_0_channels': 202,\n",
        "    'aggregation_layer_0': 'sum',\n",
        "    'neighbors_layer_0': 5\n",
        "}"
      ],
      "metadata": {
        "id": "BmZaIu6cCCyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "# Train the final model\n",
        "print(\"\\nTraining final model with oversampling...\")\n",
        "model, metrics = trainer.train_final_model_with_timesteps(best_params)"
      ],
      "metadata": {
        "id": "fBmZEVc9mYyE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d8cca0b-9448-4c3f-ba5e-462155187717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU device: NVIDIA L4\n",
            "GPU memory: 23.80 GB\n",
            "\n",
            "Training final model with oversampling...\n",
            "\n",
            "Training final model with best parameters...\n",
            "Using timesteps [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36] for training\n",
            "Using timesteps [37, 38, 39, 40, 41] for validation/threshold optimization\n",
            "Using timesteps [42, 43, 44, 45, 46, 47, 48, 49] for final evaluation\n",
            "\n",
            "Training with hyperparameters:\n",
            "  Learning rate: 4.890518499140206e-05\n",
            "  Weight decay: 0.0031518617106266154\n",
            "  Edge dropout: 0.026481649259081787\n",
            "  Focal gamma: 2.7905145019036874\n",
            "  Class weight factor: 1.0296382120174215\n",
            "  Original class weights: tensor([ 1.0844, 12.8482], device='cuda:0')\n",
            "  Scaled class weights: tensor([ 1.0844, 13.2290], device='cuda:0')\n",
            "Epoch 0: Avg Train Loss = 2.7894, Val Score = 0.4871\n",
            "  class_1_precision: 0.1856\n",
            "  class_1_recall: 0.6937\n",
            "  class_1_f1: 0.2827\n",
            "  composite_score: 0.4871\n",
            "Epoch 5: Avg Train Loss = 1.1755, Val Score = 0.5883\n",
            "  class_1_precision: 0.2487\n",
            "  class_1_recall: 0.8215\n",
            "  class_1_f1: 0.3634\n",
            "  composite_score: 0.5883\n",
            "Epoch 10: Avg Train Loss = 0.9998, Val Score = 0.6051\n",
            "  class_1_precision: 0.2558\n",
            "  class_1_recall: 0.8489\n",
            "  class_1_f1: 0.3725\n",
            "  composite_score: 0.6051\n",
            "Epoch 15: Avg Train Loss = 0.8850, Val Score = 0.6107\n",
            "  class_1_precision: 0.2817\n",
            "  class_1_recall: 0.8260\n",
            "  class_1_f1: 0.4000\n",
            "  composite_score: 0.6107\n",
            "Epoch 20: Avg Train Loss = 0.7901, Val Score = 0.6114\n",
            "  class_1_precision: 0.2844\n",
            "  class_1_recall: 0.8236\n",
            "  class_1_f1: 0.4031\n",
            "  composite_score: 0.6114\n",
            "Epoch 25: Avg Train Loss = 0.6987, Val Score = 0.6104\n",
            "  class_1_precision: 0.2830\n",
            "  class_1_recall: 0.8232\n",
            "  class_1_f1: 0.4016\n",
            "  composite_score: 0.6104\n",
            "Epoch 30: Avg Train Loss = 0.6161, Val Score = 0.6119\n",
            "  class_1_precision: 0.2837\n",
            "  class_1_recall: 0.8249\n",
            "  class_1_f1: 0.4030\n",
            "  composite_score: 0.6119\n",
            "Epoch 35: Avg Train Loss = 0.5360, Val Score = 0.6144\n",
            "  class_1_precision: 0.2835\n",
            "  class_1_recall: 0.8305\n",
            "  class_1_f1: 0.4032\n",
            "  composite_score: 0.6144\n",
            "Epoch 40: Avg Train Loss = 0.4799, Val Score = 0.6157\n",
            "  class_1_precision: 0.2840\n",
            "  class_1_recall: 0.8322\n",
            "  class_1_f1: 0.4043\n",
            "  composite_score: 0.6157\n",
            "Epoch 45: Avg Train Loss = 0.4210, Val Score = 0.6134\n",
            "  class_1_precision: 0.2852\n",
            "  class_1_recall: 0.8259\n",
            "  class_1_f1: 0.4049\n",
            "  composite_score: 0.6134\n",
            "Epoch 50: Avg Train Loss = 0.3817, Val Score = 0.6159\n",
            "  class_1_precision: 0.2838\n",
            "  class_1_recall: 0.8328\n",
            "  class_1_f1: 0.4042\n",
            "  composite_score: 0.6159\n",
            "Epoch 55: Avg Train Loss = 0.3448, Val Score = 0.6142\n",
            "  class_1_precision: 0.2869\n",
            "  class_1_recall: 0.8252\n",
            "  class_1_f1: 0.4069\n",
            "  composite_score: 0.6142\n",
            "Epoch 60: Avg Train Loss = 0.3206, Val Score = 0.6129\n",
            "  class_1_precision: 0.2847\n",
            "  class_1_recall: 0.8257\n",
            "  class_1_f1: 0.4042\n",
            "  composite_score: 0.6129\n",
            "Epoch 00062: reducing learning rate of group 0 to 2.4453e-05.\n",
            "Early stopping at epoch 65\n",
            "\n",
            "Loading best model state from training\n",
            "\n",
            "=== Finding Optimal Classification Threshold ===\n",
            "\n",
            "Optimal threshold found: 0.5700\n",
            "\n",
            "=== Evaluating Model Performance Per Timestep Starting from 37 (Using Adjusted Threshold) ===\n",
            "\n",
            "Evaluating on timestep 37:\n",
            "  Timestep type: validation\n",
            "  Composite Score: 0.8000\n",
            "  Class 1 Recall: 0.8781\n",
            "  Class 1 F1: 0.7226\n",
            "  Class 0 Recall: 0.8715\n",
            "  Class 0 F1: 0.9174\n",
            "  Balanced Acc: 0.8748\n",
            "  Precision: 0.6139\n",
            "  MCC: 0.6607\n",
            "  PR-AUC: 0.6642\n",
            "  ROC-AUC: 0.9133\n",
            "\n",
            "Evaluating on timestep 38:\n",
            "  Timestep type: validation\n",
            "  Composite Score: 0.6053\n",
            "  Class 1 Recall: 0.7600\n",
            "  Class 1 F1: 0.4431\n",
            "  Class 0 Recall: 0.8346\n",
            "  Class 0 F1: 0.8982\n",
            "  Balanced Acc: 0.7973\n",
            "  Precision: 0.3128\n",
            "  MCC: 0.4117\n",
            "  PR-AUC: 0.2773\n",
            "  ROC-AUC: 0.8451\n",
            "\n",
            "Evaluating on timestep 39:\n",
            "  Timestep type: validation\n",
            "  Composite Score: 0.5257\n",
            "  Class 1 Recall: 0.7553\n",
            "  Class 1 F1: 0.2914\n",
            "  Class 0 Recall: 0.8019\n",
            "  Class 0 F1: 0.8831\n",
            "  Balanced Acc: 0.7786\n",
            "  Precision: 0.1805\n",
            "  MCC: 0.3015\n",
            "  PR-AUC: 0.1397\n",
            "  ROC-AUC: 0.8223\n",
            "\n",
            "Evaluating on timestep 40:\n",
            "  Timestep type: validation\n",
            "  Composite Score: 0.5438\n",
            "  Class 1 Recall: 0.7353\n",
            "  Class 1 F1: 0.3455\n",
            "  Class 0 Recall: 0.8026\n",
            "  Class 0 F1: 0.8804\n",
            "  Balanced Acc: 0.7690\n",
            "  Precision: 0.2258\n",
            "  MCC: 0.3285\n",
            "  PR-AUC: 0.2205\n",
            "  ROC-AUC: 0.8159\n",
            "\n",
            "Evaluating on timestep 41:\n",
            "  Timestep type: validation\n",
            "  Composite Score: 0.5743\n",
            "  Class 1 Recall: 0.8348\n",
            "  Class 1 F1: 0.3192\n",
            "  Class 0 Recall: 0.7807\n",
            "  Class 0 F1: 0.8717\n",
            "  Balanced Acc: 0.8078\n",
            "  Precision: 0.1973\n",
            "  MCC: 0.3364\n",
            "  PR-AUC: 0.1881\n",
            "  ROC-AUC: 0.8452\n",
            "\n",
            "Evaluating on timestep 42:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.6034\n",
            "  Class 1 Recall: 0.8159\n",
            "  Class 1 F1: 0.3928\n",
            "  Class 0 Recall: 0.7971\n",
            "  Class 0 F1: 0.8793\n",
            "  Balanced Acc: 0.8065\n",
            "  Precision: 0.2587\n",
            "  MCC: 0.3828\n",
            "  PR-AUC: 0.2391\n",
            "  ROC-AUC: 0.8366\n",
            "\n",
            "Evaluating on timestep 43:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.3584\n",
            "  Class 1 Recall: 0.6090\n",
            "  Class 1 F1: 0.0933\n",
            "  Class 0 Recall: 0.7554\n",
            "  Class 0 F1: 0.8566\n",
            "  Balanced Acc: 0.6822\n",
            "  Precision: 0.0505\n",
            "  MCC: 0.1201\n",
            "  PR-AUC: 0.0452\n",
            "  ROC-AUC: 0.7114\n",
            "\n",
            "Evaluating on timestep 44:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.4707\n",
            "  Class 1 Recall: 0.7787\n",
            "  Class 1 F1: 0.1741\n",
            "  Class 0 Recall: 0.6650\n",
            "  Class 0 F1: 0.7939\n",
            "  Balanced Acc: 0.7219\n",
            "  Precision: 0.0980\n",
            "  MCC: 0.1916\n",
            "  PR-AUC: 0.1283\n",
            "  ROC-AUC: 0.7821\n",
            "\n",
            "Evaluating on timestep 45:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.3179\n",
            "  Class 1 Recall: 0.5952\n",
            "  Class 1 F1: 0.0210\n",
            "  Class 0 Recall: 0.7904\n",
            "  Class 0 F1: 0.8822\n",
            "  Balanced Acc: 0.6928\n",
            "  Precision: 0.0107\n",
            "  MCC: 0.0580\n",
            "  PR-AUC: 0.0088\n",
            "  ROC-AUC: 0.7335\n",
            "\n",
            "Evaluating on timestep 46:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.3366\n",
            "  Class 1 Recall: 0.3482\n",
            "  Class 1 F1: 0.2754\n",
            "  Class 0 Recall: 0.8435\n",
            "  Class 0 F1: 0.8742\n",
            "  Balanced Acc: 0.5959\n",
            "  Precision: 0.2278\n",
            "  MCC: 0.1608\n",
            "  PR-AUC: 0.1644\n",
            "  ROC-AUC: 0.6371\n",
            "\n",
            "Evaluating on timestep 47:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.2893\n",
            "  Class 1 Recall: 0.4102\n",
            "  Class 1 F1: 0.1257\n",
            "  Class 0 Recall: 0.8384\n",
            "  Class 0 F1: 0.9029\n",
            "  Balanced Acc: 0.6243\n",
            "  Precision: 0.0742\n",
            "  MCC: 0.1142\n",
            "  PR-AUC: 0.0654\n",
            "  ROC-AUC: 0.6773\n",
            "\n",
            "Evaluating on timestep 48:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.1945\n",
            "  Class 1 Recall: 0.1778\n",
            "  Class 1 F1: 0.1360\n",
            "  Class 0 Recall: 0.9292\n",
            "  Class 0 F1: 0.9435\n",
            "  Balanced Acc: 0.5535\n",
            "  Precision: 0.1102\n",
            "  MCC: 0.0855\n",
            "  PR-AUC: 0.1435\n",
            "  ROC-AUC: 0.7578\n",
            "\n",
            "Evaluating on timestep 49:\n",
            "  Timestep type: test\n",
            "  Composite Score: 0.3739\n",
            "  Class 1 Recall: 0.3359\n",
            "  Class 1 F1: 0.3555\n",
            "  Class 0 Recall: 0.9003\n",
            "  Class 0 F1: 0.8915\n",
            "  Balanced Acc: 0.6181\n",
            "  Precision: 0.3775\n",
            "  MCC: 0.2480\n",
            "  PR-AUC: 0.3547\n",
            "  ROC-AUC: 0.7762\n",
            "\n",
            "=== Final Evaluation on Test Set (Default Threshold) ===\n",
            "Final Test Metrics (Default Threshold):\n",
            "accuracy: 0.7401\n",
            "balanced_accuracy: 0.6424\n",
            "precision: 0.1253\n",
            "recall: 0.5249\n",
            "f1: 0.5085\n",
            "f1_micro: 0.7401\n",
            "f1_macro: 0.5085\n",
            "f1_weighted: 0.8059\n",
            "auroc: 0.7385\n",
            "auprc: 0.1502\n",
            "jaccard: 0.6949\n",
            "mcc: 0.1398\n",
            "norm_mcc: 0.5699\n",
            "kappa: 0.1000\n",
            "pr_auc: 0.1429\n",
            "class_0_precision: 0.9589\n",
            "class_0_recall: 0.7599\n",
            "class_0_f1: 0.8433\n",
            "class_0_jaccard: 0.7320\n",
            "class_0_accuracy: 0.7599\n",
            "class_1_precision: 0.1253\n",
            "class_1_recall: 0.5249\n",
            "class_1_f1: 0.1737\n",
            "class_1_jaccard: 0.0996\n",
            "class_1_accuracy: 0.5249\n",
            "composite_score: 0.3610\n",
            "\n",
            "Final Test Metrics (Adjusted Threshold = 0.5700):\n",
            "accuracy: 0.7913\n",
            "balanced_accuracy: 0.6621\n",
            "precision: 0.1510\n",
            "recall: 0.5091\n",
            "f1: 0.5374\n",
            "f1_micro: 0.7913\n",
            "f1_macro: 0.5374\n",
            "f1_weighted: 0.8407\n",
            "auroc: 0.7387\n",
            "auprc: 0.1497\n",
            "jaccard: 0.7461\n",
            "mcc: 0.1703\n",
            "norm_mcc: 0.5851\n",
            "kappa: 0.1309\n",
            "pr_auc: 0.1426\n",
            "class_0_precision: 0.9598\n",
            "class_0_recall: 0.8150\n",
            "class_0_f1: 0.8781\n",
            "class_0_jaccard: 0.7848\n",
            "class_0_accuracy: 0.8150\n",
            "class_1_precision: 0.1510\n",
            "class_1_recall: 0.5091\n",
            "class_1_f1: 0.1968\n",
            "class_1_jaccard: 0.1145\n",
            "class_1_accuracy: 0.5091\n",
            "composite_score: 0.3682\n",
            "\n",
            "Threshold Adjustment Impact:\n",
            "accuracy: 0.0512 (improvement)\n",
            "balanced_accuracy: 0.0197 (improvement)\n",
            "precision: 0.0257 (improvement)\n",
            "recall: -0.0157 (decrease)\n",
            "f1: 0.0289 (improvement)\n",
            "f1_micro: 0.0512 (improvement)\n",
            "f1_macro: 0.0289 (improvement)\n",
            "f1_weighted: 0.0347 (improvement)\n",
            "auroc: 0.0002 (improvement)\n",
            "auprc: -0.0005 (decrease)\n",
            "jaccard: 0.0513 (improvement)\n",
            "mcc: 0.0305 (improvement)\n",
            "norm_mcc: 0.0152 (improvement)\n",
            "kappa: 0.0309 (improvement)\n",
            "pr_auc: -0.0003 (decrease)\n",
            "class_0_precision: 0.0010 (improvement)\n",
            "class_0_recall: 0.0551 (improvement)\n",
            "class_0_f1: 0.0348 (improvement)\n",
            "class_0_jaccard: 0.0528 (improvement)\n",
            "class_0_accuracy: 0.0551 (improvement)\n",
            "class_1_precision: 0.0257 (improvement)\n",
            "class_1_recall: -0.0157 (decrease)\n",
            "class_1_f1: 0.0231 (improvement)\n",
            "class_1_jaccard: 0.0148 (improvement)\n",
            "class_1_accuracy: -0.0157 (decrease)\n",
            "composite_score: 0.0072 (improvement)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract embeddings for all timesteps and save to disk\n",
        "embeddings_output_path = os.path.join(save_path, \"node_embeddings.parquet\")\n",
        "embeddings_df = trainer.extract_node_embeddings(\n",
        "    model=model,\n",
        "    timesteps=None,\n",
        "    output_path=embeddings_output_path\n",
        ")\n",
        "\n",
        "print(f\"Node embeddings saved to: {embeddings_output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jGZOPWQzVJh",
        "outputId": "5ccf0275-89d0-48cc-ed9c-74c6c83cc431"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using num_neighbors: [15]\n",
            "Model structure:\n",
            "AdvancedGraphSAGE(\n",
            "  (layers): ModuleList(\n",
            "    (0): CustomSAGEConv(55, 202)\n",
            "  )\n",
            "  (linear): Linear(in_features=202, out_features=2, bias=True)\n",
            "  (dropouts): ModuleList(\n",
            "    (0): Dropout(p=0.43531998658753374, inplace=False)\n",
            "  )\n",
            "  (batch_norms): ModuleList(\n",
            "    (0): BatchNorm1d(202, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Model modules:\n",
            "  : AdvancedGraphSAGE\n",
            "  layers: ModuleList\n",
            "  layers.0: CustomSAGEConv\n",
            "  layers.0.aggr_module: SumAggregation\n",
            "  layers.0.lin_self: Linear\n",
            "  layers.0.lin_neigh: Linear\n",
            "  linear: Linear\n",
            "  dropouts: ModuleList\n",
            "  dropouts.0: Dropout\n",
            "  batch_norms: ModuleList\n",
            "  batch_norms.0: BatchNorm1d\n",
            "Processing timestep 1\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([52909, 202])\n",
            "Processing timestep 2\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([33704, 202])\n",
            "Processing timestep 3\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([31968, 202])\n",
            "Processing timestep 4\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([41675, 202])\n",
            "Processing timestep 5\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([36119, 202])\n",
            "Processing timestep 6\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([19045, 202])\n",
            "Processing timestep 7\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([32706, 202])\n",
            "Processing timestep 8\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([35921, 202])\n",
            "Processing timestep 9\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([29000, 202])\n",
            "Processing timestep 10\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([47183, 202])\n",
            "Processing timestep 11\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([30015, 202])\n",
            "Processing timestep 12\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([14094, 202])\n",
            "Processing timestep 13\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([31162, 202])\n",
            "Processing timestep 14\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([8268, 202])\n",
            "Processing timestep 15\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([19050, 202])\n",
            "Processing timestep 16\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([11954, 202])\n",
            "Processing timestep 17\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([21591, 202])\n",
            "Processing timestep 18\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([8363, 202])\n",
            "Processing timestep 19\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([15564, 202])\n",
            "Processing timestep 20\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([40587, 202])\n",
            "Processing timestep 21\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([40215, 202])\n",
            "Processing timestep 22\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([40451, 202])\n",
            "Processing timestep 23\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([22739, 202])\n",
            "Processing timestep 24\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([24205, 202])\n",
            "Processing timestep 25\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([22886, 202])\n",
            "Processing timestep 26\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([20209, 202])\n",
            "Processing timestep 27\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([10320, 202])\n",
            "Processing timestep 28\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([7649, 202])\n",
            "Processing timestep 29\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([22271, 202])\n",
            "Processing timestep 30\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([12477, 202])\n",
            "Processing timestep 31\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([19216, 202])\n",
            "Processing timestep 32\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([22396, 202])\n",
            "Processing timestep 33\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([18553, 202])\n",
            "Processing timestep 34\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([16524, 202])\n",
            "Processing timestep 35\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([31291, 202])\n",
            "Processing timestep 36\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([47252, 202])\n",
            "Processing timestep 37\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([20837, 202])\n",
            "Processing timestep 38\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([21259, 202])\n",
            "Processing timestep 39\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([14842, 202])\n",
            "Processing timestep 40\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([34598, 202])\n",
            "Processing timestep 41\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([29610, 202])\n",
            "Processing timestep 42\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([43605, 202])\n",
            "Processing timestep 43\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([32411, 202])\n",
            "Processing timestep 44\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([27383, 202])\n",
            "Processing timestep 45\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([33300, 202])\n",
            "Processing timestep 46\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([23068, 202])\n",
            "Processing timestep 47\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([28088, 202])\n",
            "Processing timestep 48\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([22854, 202])\n",
            "Processing timestep 49\n",
            "Found final classification layer: linear\n",
            "Using pre-hook on classification layer to capture embeddings\n",
            "Captured embeddings shape: torch.Size([15204, 202])\n",
            "Saving embeddings to /content/drive/My Drive/node_embeddings.parquet\n",
            "Saved embeddings successfully!\n",
            "Total rows: 1286591\n",
            "Number of embedding dimensions: 202\n",
            "Number of unique nodes: 841273\n",
            "Number of timesteps: 49\n",
            "Node embeddings saved to: /content/drive/My Drive/node_embeddings.parquet\n"
          ]
        }
      ]
    }
  ]
}